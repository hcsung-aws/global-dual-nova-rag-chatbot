import streamlit as st
import boto3
import json
import os
import re
import time
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from botocore.config import Config

st.set_page_config(page_title='ê¸€ë¡œë²Œ CS ì±—ë´‡ ğŸŒ', page_icon='ğŸŒ', layout='wide')

st.markdown('''
<div style="text-align: center; padding: 1rem 0; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 2rem;">
    <h1>ğŸŒ ê¸€ë¡œë²Œ CS ì±—ë´‡</h1>
    <p>ë‹¤êµ­ì–´ ì§€ì› ê³ ê° ì„œë¹„ìŠ¤ (Powered by Nova Micro + Nova Pro + Translation)</p>
</div>
''', unsafe_allow_html=True)

@st.cache_resource
def get_aws_clients():
    config = Config(
        read_timeout=60,
        connect_timeout=10,
        retries={'max_attempts': 3}
    )
    return {
        's3': boto3.client('s3'),
        'bedrock': boto3.client('bedrock-runtime', config=config),
        'secrets': boto3.client('secretsmanager')
    }

clients = get_aws_clients()

# ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ (í•˜ë“œì½”ë”©ìœ¼ë¡œ S3 ë¡œë“œ ì‹¤íŒ¨ ë°©ì§€)
def get_game_glossary():
    """ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (S3 ë¡œë“œ ì‹¤íŒ¨ ë°©ì§€ë¥¼ ìœ„í•´ í•˜ë“œì½”ë”©)"""
    
    # ì™„ì „í•œ ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ì„ í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ í¬í•¨
    glossary = """# ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ (í•œêµ­ì–´ <-> ì˜ì–´)
# í˜•ì‹: í•œêµ­ì–´ ìš©ì–´ | ì˜ì–´ ìš©ì–´ | ì„¤ëª…

# ìºë¦­í„° ì´ë¦„
ì£¼ì¸ê³µ | Paul | ì£¼ì¸ê³µ ìºë¦­í„° ì´ë¦„
ê³µëŒ€í•œ | Hogan | ê²Œì„ ë‚´ ìºë¦­í„° ê³µëŒ€í•œ ì´ë¦„
ë§ˆëˆ„ì—˜ | Manuel | ê²Œì„ ë‚´ ì¡°ì—° ìºë¦­í„° ì´ë¦„
ì—ì´ì „íŠ¸ C | Agent C | ê²Œì„ ë‚´ ì¡°ì—° ìºë¦­í„° ì´ë¦„

# ê¸°ë³¸ ê²Œì„ ìš©ì–´
ë ˆë²¨ì—… | Level Up | ìºë¦­í„°ì˜ ë ˆë²¨ì´ ìƒìŠ¹í•˜ëŠ” ê²ƒ
ê²½í—˜ì¹˜ | Experience Points (XP) | ìºë¦­í„° ì„±ì¥ì„ ìœ„í•œ í¬ì¸íŠ¸
ì²´ë ¥ | Health Points (HP) | ìºë¦­í„°ì˜ ìƒëª…ë ¥
ë§ˆë‚˜ | Mana Points (MP) | ë§ˆë²• ì‚¬ìš©ì„ ìœ„í•œ í¬ì¸íŠ¸
ìŠ¤í‚¬ | Skill | ìºë¦­í„°ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜ ëŠ¥ë ¥
ì•„ì´í…œ | Item | ê²Œì„ ë‚´ì—ì„œ íšë“í•  ìˆ˜ ìˆëŠ” ë¬¼ê±´
ì¸ë²¤í† ë¦¬ | Inventory | ì•„ì´í…œì„ ë³´ê´€í•˜ëŠ” ê³µê°„
í€˜ìŠ¤íŠ¸ | Quest | ê²Œì„ ë‚´ ì„ë¬´ë‚˜ ê³¼ì œ
ë˜ì „ | Dungeon | ëª¬ìŠ¤í„°ê°€ ìˆëŠ” ì§€í•˜ ê³µê°„
ë³´ìŠ¤ | Boss | ê°•ë ¥í•œ ì  ëª¬ìŠ¤í„°
ê¸¸ë“œ | Guild | í”Œë ˆì´ì–´ë“¤ì˜ ì¡°í•©ì´ë‚˜ í´ëœ
íŒŒí‹° | Party | í•¨ê»˜ ê²Œì„ì„ í•˜ëŠ” í”Œë ˆì´ì–´ ê·¸ë£¹
PvP | Player vs Player | í”Œë ˆì´ì–´ ëŒ€ í”Œë ˆì´ì–´ ì „íˆ¬
PvE | Player vs Environment | í”Œë ˆì´ì–´ ëŒ€ í™˜ê²½(ëª¬ìŠ¤í„°) ì „íˆ¬
NPC | Non-Player Character | ì»´í“¨í„°ê°€ ì¡°ì‘í•˜ëŠ” ìºë¦­í„°

# ì „íˆ¬ ê´€ë ¨ ìš©ì–´
ê³µê²©ë ¥ | Attack Power | ê³µê²© ì‹œ ê°€í•˜ëŠ” ë°ë¯¸ì§€
ë°©ì–´ë ¥ | Defense | ë°›ëŠ” ë°ë¯¸ì§€ë¥¼ ì¤„ì´ëŠ” ëŠ¥ë ¥
í¬ë¦¬í‹°ì»¬ | Critical Hit | ì¹˜ëª…íƒ€, ë†’ì€ ë°ë¯¸ì§€ë¥¼ ì£¼ëŠ” ê³µê²©
ë²„í”„ | Buff | ëŠ¥ë ¥ì¹˜ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” íš¨ê³¼
ë””ë²„í”„ | Debuff | ëŠ¥ë ¥ì¹˜ë¥¼ ê°ì†Œì‹œí‚¤ëŠ” íš¨ê³¼
íë§ | Healing | ì²´ë ¥ì„ íšŒë³µí•˜ëŠ” ê²ƒ
ë¦¬ìŠ¤í° | Respawn | ì£½ì€ í›„ ë‹¤ì‹œ ì‚´ì•„ë‚˜ëŠ” ê²ƒ
ì¿¨ë‹¤ìš´ | Cooldown | ìŠ¤í‚¬ ì¬ì‚¬ìš© ëŒ€ê¸°ì‹œê°„
ì½¤ë³´ | Combo | ì—°ì† ê³µê²©
ë„íŠ¸ ë°ë¯¸ì§€ | Damage over Time (DoT) | ì§€ì† ë°ë¯¸ì§€

# ì•„ì´í…œ ê´€ë ¨ ìš©ì–´
ì¥ë¹„ | Equipment | ìºë¦­í„°ê°€ ì°©ìš©í•˜ëŠ” ì•„ì´í…œ
ë¬´ê¸° | Weapon | ê³µê²©ìš© ì¥ë¹„
ë°©ì–´êµ¬ | Armor | ë°©ì–´ìš© ì¥ë¹„
ì†Œëª¨í’ˆ | Consumable | ì‚¬ìš©í•˜ë©´ ì—†ì–´ì§€ëŠ” ì•„ì´í…œ
ë ˆì–´ ì•„ì´í…œ | Rare Item | í¬ê·€í•œ ì•„ì´í…œ
ì—í”½ ì•„ì´í…œ | Epic Item | ë§¤ìš° í¬ê·€í•œ ì•„ì´í…œ
ë ˆì „ë”ë¦¬ | Legendary | ì „ì„¤ê¸‰ ì•„ì´í…œ
ì„¸íŠ¸ ì•„ì´í…œ | Set Item | ì„¸íŠ¸ë¡œ ì°©ìš©í•˜ë©´ ì¶”ê°€ íš¨ê³¼ê°€ ìˆëŠ” ì•„ì´í…œ
ê°•í™” | Enhancement/Upgrade | ì•„ì´í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒ
ì¸ì±ˆíŠ¸ | Enchant | ì•„ì´í…œì— ë§ˆë²• íš¨ê³¼ë¥¼ ë¶€ì—¬í•˜ëŠ” ê²ƒ

# ê²Œì„ ì‹œìŠ¤í…œ ìš©ì–´
ì„œë²„ | Server | ê²Œì„ì´ ìš´ì˜ë˜ëŠ” ì»´í“¨í„°
ì±„ë„ | Channel | ì„œë²„ ë‚´ì˜ êµ¬ì—­
ë¡œê·¸ì¸ | Login | ê²Œì„ì— ì ‘ì†í•˜ëŠ” ê²ƒ
ë¡œê·¸ì•„ì›ƒ | Logout | ê²Œì„ì—ì„œ ë‚˜ê°€ëŠ” ê²ƒ
ì„¸ì´ë¸Œ | Save | ê²Œì„ ì§„í–‰ ìƒí™©ì„ ì €ì¥í•˜ëŠ” ê²ƒ
ë¡œë“œ | Load | ì €ì¥ëœ ê²Œì„ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒ
íŒ¨ì¹˜ | Patch | ê²Œì„ ì—…ë°ì´íŠ¸
ë²„ê·¸ | Bug | ê²Œì„ì˜ ì˜¤ë¥˜ë‚˜ ê²°í•¨
ë˜ê·¸ | Lag | ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ëŠê¹€ í˜„ìƒ
í•‘ | Ping | ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ ì†ë„

# ìºë¦­í„° ê´€ë ¨ ìš©ì–´
ìºë¦­í„° | Character | í”Œë ˆì´ì–´ê°€ ì¡°ì‘í•˜ëŠ” ê²Œì„ ë‚´ ì¸ë¬¼
í´ë˜ìŠ¤ | Class | ìºë¦­í„°ì˜ ì§ì—…ì´ë‚˜ ìœ í˜•
ìŠ¤íƒ¯ | Stats | ìºë¦­í„°ì˜ ëŠ¥ë ¥ì¹˜
ìŠ¤í‚¬ íŠ¸ë¦¬ | Skill Tree | ìŠ¤í‚¬ ìŠµë“ ì²´ê³„
ë¦¬ë¡¤ | Reroll | ìºë¦­í„°ë¥¼ ë‹¤ì‹œ ë§Œë“œëŠ” ê²ƒ
ì»¤ìŠ¤í„°ë§ˆì´ì§• | Customization | ìºë¦­í„° ì™¸í˜• ë³€ê²½
ì•„ë°”íƒ€ | Avatar | í”Œë ˆì´ì–´ë¥¼ ëŒ€í‘œí•˜ëŠ” ìºë¦­í„°
ë‹‰ë„¤ì„ | Nickname | ê²Œì„ ë‚´ ì‚¬ìš©ì ì´ë¦„

# ê²Œì„ í”Œë ˆì´ ìš©ì–´
íŒŒë° | Farming | ì•„ì´í…œì´ë‚˜ ê²½í—˜ì¹˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ íšë“í•˜ëŠ” ê²ƒ
ê·¸ë¼ì¸ë”© | Grinding | ë°˜ë³µì ì¸ ì‘ì—…ì„ í†µí•œ ì„±ì¥
ìŠ¤í”¼ë“œëŸ° | Speedrun | ìµœë‹¨ ì‹œê°„ ë‚´ ê²Œì„ í´ë¦¬ì–´
ì†”ë¡œ í”Œë ˆì´ | Solo Play | í˜¼ìì„œ ê²Œì„í•˜ëŠ” ê²ƒ
ë©€í‹° í”Œë ˆì´ | Multiplayer | ì—¬ëŸ¬ ëª…ì´ í•¨ê»˜ ê²Œì„í•˜ëŠ” ê²ƒ
ë­í‚¹ | Ranking | ìˆœìœ„
ë¦¬ë”ë³´ë“œ | Leaderboard | ìˆœìœ„í‘œ
í† ë„ˆë¨¼íŠ¸ | Tournament | ê²½ê¸° ëŒ€íšŒ
ì‹œì¦Œ | Season | ê²Œì„ì˜ íŠ¹ì • ê¸°ê°„
ì´ë²¤íŠ¸ | Event | íŠ¹ë³„í•œ ê²Œì„ ë‚´ í–‰ì‚¬

# ì˜¨ë¼ì¸ ê²Œì„ ìš©ì–´
ë§¤ì¹˜ë©”ì´í‚¹ | Matchmaking | ë¹„ìŠ·í•œ ì‹¤ë ¥ì˜ í”Œë ˆì´ì–´ë¼ë¦¬ ë§¤ì¹­
ë¡œë¹„ | Lobby | ê²Œì„ ì‹œì‘ ì „ ëŒ€ê¸°ì‹¤
ë°© ë§Œë“¤ê¸° | Create Room | ê²Œì„ë°© ìƒì„±
ë°© ì°¸ê°€ | Join Room | ê²Œì„ë°© ì…ì¥
í‚¥ | Kick | í”Œë ˆì´ì–´ë¥¼ ê°•ì œë¡œ ë‚´ë³´ë‚´ëŠ” ê²ƒ
ë°´ | Ban | ê³„ì • ì •ì§€
ì‹ ê³  | Report | ë¶€ì •í–‰ìœ„ë‚˜ ìš•ì„¤ ì‹ ê³ 
ì±„íŒ… | Chat | í…ìŠ¤íŠ¸ë¡œ ëŒ€í™”í•˜ëŠ” ê²ƒ
ìŒì„± ì±„íŒ… | Voice Chat | ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ëŠ” ê²ƒ
ì¹œêµ¬ ì¶”ê°€ | Add Friend | ì¹œêµ¬ ëª©ë¡ì— ì¶”ê°€

# ëª¨ë°”ì¼ ê²Œì„ ìš©ì–´
ê°€ì±  | Gacha | ëœë¤ ë½‘ê¸° ì‹œìŠ¤í…œ
ë½‘ê¸° | Draw/Pull | ëœë¤ìœ¼ë¡œ ì•„ì´í…œì´ë‚˜ ìºë¦­í„° íšë“
ê³¼ê¸ˆ | In-app Purchase | ê²Œì„ ë‚´ ê²°ì œ
ë¬´ê³¼ê¸ˆ | Free-to-play | ëˆì„ ì“°ì§€ ì•Šê³  ê²Œì„í•˜ëŠ” ê²ƒ
ì†Œê³¼ê¸ˆ | Light Spender | ì ì€ ê¸ˆì•¡ë§Œ ê²°ì œí•˜ëŠ” ê²ƒ
ì¤‘ê³¼ê¸ˆ | Medium Spender | ì¤‘ê°„ ì •ë„ ê¸ˆì•¡ì„ ê²°ì œí•˜ëŠ” ê²ƒ
ê³ ê³¼ê¸ˆ | Heavy Spender | ë§ì€ ê¸ˆì•¡ì„ ê²°ì œí•˜ëŠ” ê²ƒ
ì¼ì¼ ë¯¸ì…˜ | Daily Mission | ë§¤ì¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì„ë¬´
ì£¼ê°„ ë¯¸ì…˜ | Weekly Mission | ë§¤ì£¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì„ë¬´
ì¶œì„ ì²´í¬ | Daily Check-in | ë§¤ì¼ ì ‘ì† ë³´ìƒ
ìŠ¤íƒœë¯¸ë‚˜ | Stamina | ê²Œì„ í”Œë ˆì´ë¥¼ ìœ„í•œ ì—ë„ˆì§€

# CS ê´€ë ¨ ìš©ì–´
ê³ ê° ì§€ì› | Customer Support | ê³ ê° ì„œë¹„ìŠ¤
ë¬¸ì˜ | Inquiry | ì§ˆë¬¸ì´ë‚˜ ìš”ì²­
ì‹ ê³  | Report | ë¬¸ì œ ìƒí™© ì•Œë¦¼
í™˜ë¶ˆ | Refund | ê²°ì œ ì·¨ì†Œ ë° ëˆ ëŒë ¤ë°›ê¸°
ê³„ì • ë³µêµ¬ | Account Recovery | ìƒì–´ë²„ë¦° ê³„ì • ë˜ì°¾ê¸°
ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì • | Password Reset | ë¹„ë°€ë²ˆí˜¸ ë³€ê²½
ë¡œê·¸ì¸ ë¬¸ì œ | Login Issue | ì ‘ì† ê´€ë ¨ ë¬¸ì œ
ê²°ì œ ë¬¸ì œ | Payment Issue | ê²°ì œ ê´€ë ¨ ë¬¸ì œ
ê²Œì„ ì˜¤ë¥˜ | Game Error | ê²Œì„ ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ë¬¸ì œ
ì—°ê²° ë¬¸ì œ | Connection Issue | ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ"""
    
    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
    print(f"=== í•˜ë“œì½”ë”©ëœ ë‹¨ì–´ì¥ ë¡œë“œ ===")
    print(f"ë‹¨ì–´ì¥ í¬ê¸°: {len(glossary)} ë¬¸ì")
    print(f"Paul í¬í•¨ ì—¬ë¶€: {'Paul' in glossary}")
    print(f"Hogan í¬í•¨ ì—¬ë¶€: {'Hogan' in glossary}")
    print(f"Manuel í¬í•¨ ì—¬ë¶€: {'Manuel' in glossary}")
    print(f"Agent C í¬í•¨ ì—¬ë¶€: {'Agent C' in glossary}")
    print("=" * 30)
    
    return glossary

# ë²ˆì—­ ê´€ë ¨ í•¨ìˆ˜ë“¤
def create_translation_prompt_prefix():
    """ë²ˆì—­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ prefix ìƒì„± (ìºì‹±ìš©)"""
    glossary = get_game_glossary()  # í•˜ë“œì½”ë”©ëœ ë‹¨ì–´ì¥ ì‚¬ìš©
    
    prefix = f"""You are a professional real-time chat translator specializing in gaming and customer service terminology. 
Your mission is to translate messages between Korean and English while maintaining gaming context and customer service tone.

## Your Role and Expertise
- Expert gaming translator with deep knowledge of gaming terminology
- Customer service specialist familiar with CS communication patterns
- Cultural bridge helping global gamers communicate effectively
- Maintain professional yet friendly tone appropriate for customer service

## Translation Guidelines
1. **Gaming Context Priority**: Always prioritize gaming-specific meanings over general translations
2. **Customer Service Tone**: Maintain professional, helpful, and friendly tone
3. **Cultural Adaptation**: Adapt expressions to be natural in target language
4. **Consistency**: Use consistent terminology throughout conversations
5. **Clarity**: Ensure translations are clear and unambiguous

## Game Terminology Glossary (CRITICAL - Use this for character and term recognition)
{glossary}

## Special Instructions
- For Korean to English: Use natural English expressions that English-speaking gamers would use
- For English to Korean: Use Korean gaming terminology that Korean gamers are familiar with
- Preserve emotional tone and urgency level of the original message
- If uncertain about gaming terms, use the most commonly accepted translation
- For customer service contexts, maintain professional courtesy markers
- Always use the glossary above for accurate gaming terminology translation

## Output Format Requirements
- Provide only the translated text
- Maintain natural flow in the target language
- Use appropriate gaming terminology from the glossary

"""
    return prefix

def log_token_usage(model_id, response_body, operation="chat"):
    """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… í•¨ìˆ˜"""
    try:
        usage = response_body.get('usage', {})
        input_tokens = usage.get('inputTokens', 0)
        output_tokens = usage.get('outputTokens', 0)
        total_tokens = usage.get('totalTokens', 0)
        cache_read_tokens = usage.get('cacheReadInputTokenCount', 0)
        cache_write_tokens = usage.get('cacheWriteInputTokenCount', 0)
        
        # ë¡œê·¸ ì¶œë ¥
        print(f"=== í† í° ì‚¬ìš©ëŸ‰ ({operation}) ===")
        print(f"ëª¨ë¸: {model_id}")
        print(f"ì…ë ¥ í† í°: {input_tokens:,}")
        print(f"ì¶œë ¥ í† í°: {output_tokens:,}")
        print(f"ì´ í† í°: {total_tokens:,}")
        print(f"ìºì‹œ ì½ê¸° í† í°: {cache_read_tokens:,}")
        print(f"ìºì‹œ ì“°ê¸° í† í°: {cache_write_tokens:,}")
        
        # ìºì‹± íš¨ê³¼ ê³„ì‚°
        if cache_read_tokens > 0:
            cache_efficiency = (cache_read_tokens / input_tokens) * 100 if input_tokens > 0 else 0
            print(f"ìºì‹± íš¨ìœ¨: {cache_efficiency:.1f}%")
            
            # Streamlitì— ìºì‹± íš¨ê³¼ í‘œì‹œ
            st.sidebar.success(f"ğŸš€ ìºì‹œ íš¨ìœ¨: {cache_efficiency:.1f}% ({cache_read_tokens:,} í† í° ì ˆì•½)")
        
        print("=" * 40)
        
    except Exception as e:
        print(f"í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ì˜¤ë¥˜: {e}")

def translate_text_with_caching(text, target_language="auto"):
    """Nova Proë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ í•¨ìˆ˜ (Nova ì „ìš© í”„ë¡¬í”„íŠ¸ ìºì‹±)"""
    
    # ì–¸ì–´ ê°ì§€ ë° íƒ€ê²Ÿ ì–¸ì–´ ì„¤ì •
    if target_language == "auto":
        # ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€ (í•œê¸€ í¬í•¨ ì—¬ë¶€ë¡œ íŒë‹¨)
        if re.search(r'[ê°€-í£]', text):
            target_language = "English"
            detected_language = "Korean"
        else:
            target_language = "Korean"
            detected_language = "English"
    else:
        detected_language = "Korean" if target_language == "English" else "English"
    
    # Prefix (ìºì‹±ë  ë¶€ë¶„) - ë‹¨ì–´ì¥ í¬í•¨
    prefix_prompt = create_translation_prompt_prefix()
    
    # Suffix (ë³€ë™ë˜ëŠ” ë¶€ë¶„) - ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸
    suffix_prompt = f"""
Translate the following text from {detected_language} to {target_language}:

Text to translate: "{text}"

Please provide only the translation result in {target_language}. Use the game terminology glossary above for accurate character and term recognition.

Translation:"""

    try:
        # Nova Proë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ ìš”ì²­ (Nova ì „ìš© ìºì‹±)
        message = {
            "role": "user",
            "content": [
                {"text": prefix_prompt, "cachePoint": {"type": "default"}},  # Nova ì „ìš© ìºì‹±
                {"text": suffix_prompt}
            ]
        }
        
        body = {
            "messages": [message],
            "inferenceConfig": {
                "max_new_tokens": 500,
                "temperature": 0.1  # ë²ˆì—­ì€ ë‚®ì€ temperature ì‚¬ìš©
            }
        }
        
        response = clients['bedrock'].invoke_model(
            body=json.dumps(body),
            modelId='amazon.nova-pro-v1:0',
            accept='application/json',
            contentType='application/json'
        )
        
        response_body = json.loads(response.get('body').read())
        translated_content = response_body['output']['message']['content'][0]['text'].strip()
        
        # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
        log_token_usage('amazon.nova-pro-v1:0', response_body, f"ë²ˆì—­({target_language})")
        
        # ë””ë²„ê¹… ì •ë³´
        print(f"=== Nova ë²ˆì—­ ë””ë²„ê¹… ===")
        print(f"ì…ë ¥: {text}")
        print(f"ì¶œë ¥: {translated_content}")
        print(f"íƒ€ê²Ÿ ì–¸ì–´: {target_language}")
        print("=" * 25)
        
        # ë²ˆì—­ ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì›ë³¸ê³¼ ë™ì¼í•œ ê²½ìš° ì²˜ë¦¬
        if not translated_content or translated_content == text:
            print("ë²ˆì—­ ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì›ë³¸ê³¼ ë™ì¼í•¨")
            translated_content = text
        
        return {
            "original_text": text,
            "detected_language": detected_language,
            "target_language": target_language,
            "translated_text": translated_content
        }
            
    except Exception as e:
        print(f"ë²ˆì—­ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        return {
            "original_text": text,
            "detected_language": detected_language,
            "target_language": target_language,
            "translated_text": text
        }



def extract_keywords(query):
    """ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
    # ë¶ˆìš©ì–´ ì œê±°
    stop_words = {'ì—', 'ëŒ€í•´', 'ëŒ€í•´ì„œ', 'ì—ì„œ', 'ë¥¼', 'ì„', 'ê°€', 'ì´', 'ì€', 'ëŠ”', 'ì˜', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ë¶€í„°', 'ê¹Œì§€', 'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'about', 'how', 'what', 'when', 'where', 'why', 'who'}
    
    # ì¡°ì‚¬ ì œê±°ë¥¼ ìœ„í•œ íŒ¨í„´
    query_cleaned = re.sub(r'(ì—ì„œ|ì—ê²Œ|ì—|ë¥¼|ì„|ê°€|ì´|ì€|ëŠ”|ì˜|ì™€|ê³¼|ë¡œ|ìœ¼ë¡œ|í•œí…Œ|ê»˜|ë¶€í„°|ê¹Œì§€)(?=\s|$)', '', query)
    
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ë‹¨ì–´ ë¶„ë¦¬
    words = re.findall(r'\b\w+\b', query_cleaned.lower())
    keywords = [word for word in words if word not in stop_words and len(word) > 1]
    
    # ì¶”ê°€ë¡œ ì›ë³¸ ì¿¼ë¦¬ì—ì„œë„ í‚¤ì›Œë“œ ì¶”ì¶œ
    original_words = re.findall(r'\b\w+\b', query.lower())
    for word in original_words:
        if word not in stop_words and len(word) > 1 and word not in keywords:
            keywords.append(word)
    
    return list(set(keywords))  # ì¤‘ë³µ ì œê±°

def search_knowledge_base(query, max_results=5):
    """Bedrock Knowledge Baseì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
    try:
        # Bedrock Agent Runtime í´ë¼ì´ì–¸íŠ¸
        bedrock_agent_client = boto3.client('bedrock-agent-runtime', region_name='us-east-1')
        
        response = bedrock_agent_client.retrieve(
            knowledgeBaseId='SJJP9YYPHX',
            retrievalQuery={
                'text': query
            },
            retrievalConfiguration={
                'vectorSearchConfiguration': {
                    'numberOfResults': max_results
                }
            }
        )
        
        results = []
        for result in response.get('retrievalResults', []):
            content = result.get('content', {}).get('text', '')
            score = result.get('score', 0)
            location = result.get('location', {})
            
            # S3 locationì—ì„œ ì œëª© ì¶”ì¶œ ì‹œë„
            title = "Knowledge Base Document"
            if 's3Location' in location:
                s3_uri = location['s3Location'].get('uri', '')
                if s3_uri:
                    # S3 URIì—ì„œ íŒŒì¼ëª… ì¶”ì¶œí•˜ì—¬ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
                    title = s3_uri.split('/')[-1].replace('.json', '').replace('.txt', '').replace('_', ' ')
            
            results.append({
                'title': title,
                'content': content,
                'url': location.get('s3Location', {}).get('uri', '#'),
                'score': score,
                'matched_keywords': []  # Knowledge BaseëŠ” ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ì„± ìë™ ê³„ì‚°
            })
        
        return results
        
    except Exception as e:
        print(f"Knowledge Base ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        st.error(f"Knowledge Base ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def create_answer_prompt_prefix(user_language="Korean"):
    """ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ prefix ìƒì„± (ìºì‹±ìš©)"""
    glossary = get_game_glossary()  # í•˜ë“œì½”ë”©ëœ ë‹¨ì–´ì¥ ì‚¬ìš©
    
    # ë‹¨ì–´ì¥ ë¡œë“œ ìƒíƒœ ë””ë²„ê¹…
    print(f"=== ë‹µë³€ í”„ë¡¬í”„íŠ¸ ìƒì„± ë””ë²„ê¹… ===")
    print(f"ì–¸ì–´: {user_language}")
    print(f"ë‹¨ì–´ì¥ í¬ê¸°: {len(glossary)} ë¬¸ì")
    print(f"Paul í¬í•¨: {'Paul' in glossary}")
    print(f"Hogan í¬í•¨: {'Hogan' in glossary}")
    print(f"Manuel í¬í•¨: {'Manuel' in glossary}")
    print(f"Agent C í¬í•¨: {'Agent C' in glossary}")
    print("=" * 40)
    
    if user_language == "English":
        prefix = f"""You are a professional Global Customer Service AI assistant specializing in gaming support and technical assistance.
Your mission is to provide accurate, helpful, and friendly customer service responses based on provided documentation.

## Your Role and Expertise
- Expert gaming customer service representative with deep knowledge of gaming terminology
- Technical support specialist familiar with troubleshooting and problem-solving
- Professional communicator maintaining friendly yet informative tone
- Cultural bridge helping global gamers with their inquiries

## Game Terminology Glossary (CRITICAL - Use this for character and term recognition)
{glossary}

## Response Guidelines
1. **Accuracy First**: Base all answers strictly on provided documentation
2. **Gaming Context**: Always prioritize gaming-specific meanings and context
3. **Professional Tone**: Maintain helpful, friendly, and professional customer service tone
4. **Clarity**: Provide clear, step-by-step explanations when needed
5. **Completeness**: Address all aspects of the user's question
6. **Consistency**: Use consistent terminology throughout responses

## Special Instructions
- Always use the glossary above for accurate character and term recognition
- For technical issues, provide systematic troubleshooting steps
- For game features, explain benefits and usage clearly
- Always maintain a helpful customer service attitude
- Use the glossary terms consistently throughout your response

"""
    else:
        prefix = f"""ë‹¹ì‹ ì€ ê²Œì„ ì§€ì› ë° ê¸°ìˆ  ì§€ì›ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ê¸€ë¡œë²Œ ê³ ê° ì„œë¹„ìŠ¤ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì¹œê·¼í•œ ê³ ê° ì„œë¹„ìŠ¤ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤.

## ë‹¹ì‹ ì˜ ì—­í• ê³¼ ì „ë¬¸ì„±
- ê²Œì„ ìš©ì–´ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§„ ì „ë¬¸ ê²Œì„ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ì
- ë¬¸ì œ í•´ê²°ê³¼ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ì— ìµìˆ™í•œ ê¸°ìˆ  ì§€ì› ì „ë¬¸ê°€
- ì¹œê·¼í•˜ë©´ì„œë„ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ëŠ” ì „ë¬¸ ì»¤ë®¤ë‹ˆì¼€ì´í„°
- ì „ ì„¸ê³„ ê²Œì´ë¨¸ë“¤ì˜ ë¬¸ì˜ë¥¼ ë„ì™€ì£¼ëŠ” ë¬¸í™”ì  ê°€êµ ì—­í• 

## ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ (ì¤‘ìš” - ìºë¦­í„° ë° ìš©ì–´ ì¸ì‹ì— ì‚¬ìš©)
{glossary}

## ì‘ë‹µ ê°€ì´ë“œë¼ì¸
1. **ì •í™•ì„± ìš°ì„ **: ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë“  ë‹µë³€ì„ ì •í™•í•˜ê²Œ ì‘ì„±
2. **ê²Œì„ ë§¥ë½**: í•­ìƒ ê²Œì„ íŠ¹í™” ì˜ë¯¸ì™€ ë§¥ë½ì„ ìš°ì„ ì‹œ
3. **ì „ë¬¸ì  í†¤**: ë„ì›€ì´ ë˜ê³  ì¹œê·¼í•˜ë©° ì „ë¬¸ì ì¸ ê³ ê° ì„œë¹„ìŠ¤ í†¤ ìœ ì§€
4. **ëª…í™•ì„±**: í•„ìš”ì‹œ ëª…í™•í•˜ê³  ë‹¨ê³„ë³„ ì„¤ëª… ì œê³µ
5. **ì™„ì „ì„±**: ì‚¬ìš©ì ì§ˆë¬¸ì˜ ëª¨ë“  ì¸¡ë©´ì„ ë‹¤ë£¸
6. **ì¼ê´€ì„±**: ì‘ë‹µ ì „ë°˜ì— ê±¸ì³ ì¼ê´€ëœ ìš©ì–´ ì‚¬ìš©

## íŠ¹ë³„ ì§€ì‹œì‚¬í•­
- ìœ„ì˜ ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ì„ í™œìš©í•˜ì—¬ ì •í™•í•œ ìºë¦­í„° ë° ìš©ì–´ ì¸ì‹
- ê¸°ìˆ ì  ë¬¸ì œì˜ ê²½ìš° ì²´ê³„ì ì¸ ë¬¸ì œ í•´ê²° ë‹¨ê³„ ì œê³µ
- ê²Œì„ ê¸°ëŠ¥ì˜ ê²½ìš° ì¥ì ê³¼ ì‚¬ìš©ë²•ì„ ëª…í™•íˆ ì„¤ëª…
- í•­ìƒ ë„ì›€ì´ ë˜ëŠ” ê³ ê° ì„œë¹„ìŠ¤ íƒœë„ ìœ ì§€
- ì‘ë‹µ ì „ë°˜ì— ê±¸ì³ ë‹¨ì–´ì¥ì˜ ìš©ì–´ë¥¼ ì¼ê´€ë˜ê²Œ ì‚¬ìš©

"""
    return prefix

def create_prompts(user_query, context_docs, conversation_history, user_language="Korean"):
    """ê° ëª¨ë¸ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„± (ë‹¤êµ­ì–´ ì§€ì›, ìºì‹± ìµœì í™”)"""
    
    # ìºì‹± ê°€ëŠ¥í•œ prefix ìƒì„±
    cached_prefix = create_answer_prompt_prefix(user_language)
    
    # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    context = ""
    if context_docs:
        context = "\n\n".join([f"ì œëª©: {doc['title']}\në‚´ìš©: {doc['content'][:1000]}" for doc in context_docs])
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¤€ë¹„
    history_context = ""
    if conversation_history:
        recent_history = conversation_history[-4:]
        history_parts = []
        for i in range(0, len(recent_history), 2):
            if i + 1 < len(recent_history):
                history_parts.append(f"ì´ì „ ì§ˆë¬¸: {recent_history[i]['content']}\nì´ì „ ë‹µë³€: {recent_history[i + 1]['content']}")
        if history_parts:
            history_context = f"ì´ì „ ëŒ€í™”:\n{chr(10).join(history_parts)}\n\n"
    
    # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì • (ìºì‹±ëœ prefix í™œìš©)
    if user_language == "English":
        # ì˜ì–´ ì‚¬ìš©ìë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        micro_prompt = f"""{cached_prefix}

## Current Task: Provide Concise Overview

{history_context}Based on the following documents, please provide a concise overview:

{context}

Question: {user_query}

Requirements:
- Provide key information in 1-2 paragraphs clearly and concisely
- End with complete sentences
- Finish with a simple connecting phrase like "Let me provide more details."
- Respond in English in a friendly manner
- Keep it brief to avoid incomplete responses
- Use the game terminology glossary above for accurate character and term recognition

Answer:"""

        pro_prompt = f"""{cached_prefix}

## Current Task: Provide Detailed Analysis

{history_context}I previously provided a basic overview for "{user_query}". 
Now, please provide more detailed and professional analysis based on the following documents:

{context}

Question: {user_query}

Requirements:
- Start naturally as an extension of the previous answer (e.g., "Looking more specifically...", "To analyze this in more detail...")
- Include specific examples, pros/cons, use cases, and comparative analysis
- Use markdown for structured and organized answers
- Provide practical and professional insights
- Respond in English in a friendly and professional manner
- Base your answer accurately and in detail on the provided documents
- Explain step-by-step when necessary
- Consider previous conversation context
- Use the game terminology glossary above for accurate character and term recognition

Answer:"""
    else:
        # í•œêµ­ì–´ ì‚¬ìš©ìë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´)
        micro_prompt = f"""{cached_prefix}

## í˜„ì¬ ì‘ì—…: ê°„ê²°í•œ ê°œìš” ì œê³µ

{history_context}ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ê°„ê²°í•œ ê°œìš”ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

{context}

ì§ˆë¬¸: {user_query}

ìš”êµ¬ì‚¬í•­:
- í•µì‹¬ ë‚´ìš©ì„ 1-2ê°œ ë¬¸ë‹¨ìœ¼ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…
- ë°˜ë“œì‹œ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•  ê²ƒ
- ë§ˆì§€ë§‰ì— "ë” êµ¬ì²´ì ìœ¼ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤." ê°™ì€ ê°„ë‹¨í•œ ì—°ê²° ë¬¸êµ¬ë¡œ ë§ˆë¬´ë¦¬
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì—¬ ë‹µë³€ì´ ì¤‘ê°„ì— ëŠì–´ì§€ì§€ ì•Šë„ë¡ í•´ì£¼ì„¸ìš”
- ìœ„ì˜ ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ì„ í™œìš©í•˜ì—¬ ì •í™•í•œ ìºë¦­í„° ë° ìš©ì–´ ì¸ì‹

ë‹µë³€:"""

        pro_prompt = f"""{cached_prefix}

## í˜„ì¬ ì‘ì—…: ìƒì„¸í•œ ë¶„ì„ ì œê³µ

{history_context}ì•ì„œ "{user_query}"ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ê°œìš”ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤. 
ì´ì œ ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ê·¸ ë‚´ìš©ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ë” ìƒì„¸í•˜ê³  ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:

{context}

ì§ˆë¬¸: {user_query}

ìš”êµ¬ì‚¬í•­:
- ì•ì„  ë‹µë³€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ì¥ì„ ìƒì—ì„œ ì‹œì‘ (ì˜ˆ: "ë” êµ¬ì²´ì ìœ¼ë¡œ ì‚´í´ë³´ë©´...", "ì´ë¥¼ ë” ìì„¸íˆ ë¶„ì„í•˜ë©´..." ë“±)
- êµ¬ì²´ì ì¸ ì˜ˆì‹œ, ì¥ë‹¨ì , ì‚¬ìš© ì‚¬ë¡€, ë¹„êµ ë¶„ì„ì„ í¬í•¨í•œ ì‹¬í™” ë‚´ìš©
- ë§ˆí¬ë‹¤ìš´ì„ í™œìš©í•œ ì²´ê³„ì ì´ê³  êµ¬ì¡°í™”ëœ ë‹µë³€
- ì‹¤ë¬´ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ì ì—ì„œì˜ ê¹Šì´ ìˆëŠ” ì„¤ëª…
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- í•„ìš”ì‹œ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
- ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ìœ„ì˜ ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ì„ í™œìš©í•˜ì—¬ ì •í™•í•œ ìºë¦­í„° ë° ìš©ì–´ ì¸ì‹

ë‹µë³€:"""

    return micro_prompt, pro_prompt

def stream_nova_model(model_id, prompt, max_tokens=500, temperature=0.3):
    """Nova ëª¨ë¸ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (Nova ì „ìš© í”„ë¡¬í”„íŠ¸ ìºì‹±)"""
    
    # í”„ë¡¬í”„íŠ¸ë¥¼ ìºì‹± ê°€ëŠ¥í•œ ë¶€ë¶„ê³¼ ë™ì  ë¶€ë¶„ìœ¼ë¡œ ë¶„ë¦¬
    lines = prompt.split('\n')
    
    # ìºì‹± ê²½ê³„ ì°¾ê¸° (ë” ì •í™•í•œ ê°ì§€)
    cache_boundary = -1
    for i, line in enumerate(lines):
        if any(marker in line for marker in [
            "## Current Task:", "## í˜„ì¬ ì‘ì—…:", 
            "Based on the following documents", "ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬",
            "I previously provided", "ì•ì„œ",
            "Question:", "ì§ˆë¬¸:",
            "Requirements:", "ìš”êµ¬ì‚¬í•­:"
        ]):
            cache_boundary = i
            break
    
    # ìºì‹± ê²½ê³„ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, í”„ë¡¬í”„íŠ¸ ê¸¸ì´ì˜ 60% ì§€ì ì„ ê²½ê³„ë¡œ ì„¤ì •
    if cache_boundary == -1 and len(lines) > 10:
        cache_boundary = int(len(lines) * 0.6)
        print(f"=== ìë™ ìºì‹± ê²½ê³„ ì„¤ì • ===")
        print(f"ê²½ê³„ë¥¼ ì°¾ì§€ ëª»í•´ {cache_boundary}ë²ˆì§¸ ì¤„ë¡œ ì„¤ì •")
        print("=" * 30)
    
    messages = []
    
    if cache_boundary > 3:  # ìµœì†Œ ìºì‹± ì¡°ê±´ ì™„í™” (5 â†’ 3)
        # ìºì‹± ê°€ëŠ¥í•œ ë¶€ë¶„ (ë‹¨ì–´ì¥ + ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­)
        cached_content = '\n'.join(lines[:cache_boundary])
        
        # ë””ë²„ê¹…: ìºì‹± ì •ë³´ ì¶œë ¥
        print(f"=== Nova í”„ë¡¬í”„íŠ¸ ìºì‹± ===")
        print(f"ì „ì²´ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        print(f"ìºì‹± ë¶€ë¶„ ê¸¸ì´: {len(cached_content)} ë¬¸ì")
        print(f"ìºì‹± ë¹„ìœ¨: {len(cached_content)/len(prompt)*100:.1f}%")
        print(f"ìºì‹± ê²½ê³„: {cache_boundary}ë²ˆì§¸ ì¤„")
        print("=" * 30)
        
        # Nova ëª¨ë¸ìš© ìºì‹± êµ¬ì¡° (cachePoint ì‚¬ìš©)
        messages.append({
            "role": "user",
            "content": [
                {"text": cached_content, "cachePoint": {"type": "default"}}  # Nova ëª¨ë¸ìš© ìºì‹±
            ]
        })
        
        # ë™ì  ë¶€ë¶„
        dynamic_content = '\n'.join(lines[cache_boundary:])
        messages.append({
            "role": "user", 
            "content": [{"text": dynamic_content}]
        })
    else:
        # ìºì‹± êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬
        print(f"=== ìºì‹± ë¶ˆê°€ ===")
        print(f"ìºì‹± ê²½ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ê²½ê³„: {cache_boundary})")
        print("ì „ì²´ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¨ì¼ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬")
        print("=" * 20)
        
        messages.append({
            "role": "user",
            "content": [{"text": prompt}]
        })

    body = {
        "messages": messages,
        "inferenceConfig": {
            "max_new_tokens": max_tokens,
            "temperature": temperature
        }
    }

    try:
        response = clients['bedrock'].invoke_model_with_response_stream(
            body=json.dumps(body),
            modelId=model_id,
            accept='application/json',
            contentType='application/json'
        )
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        stream = response.get('body')
        if stream:
            for event in stream:
                chunk = event.get('chunk')
                if chunk:
                    chunk_obj = json.loads(chunk.get('bytes').decode())
                    
                    # contentBlockDeltaì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    if 'contentBlockDelta' in chunk_obj:
                        delta = chunk_obj['contentBlockDelta'].get('delta', {})
                        text_content = delta.get('text', '')
                        if text_content:
                            yield text_content
                    
                    # ë©”íƒ€ë°ì´í„°ì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ ì¶”ì¶œ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œ)
                    if 'messageStop' in chunk_obj:
                        metadata = chunk_obj.get('messageStop', {})
                        if 'stopReason' in metadata:
                            print(f"ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {metadata.get('stopReason')}")
                            
    except Exception as e:
        yield f"âŒ {model_id} ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}"

def generate_dual_language_response(query, context_docs, conversation_history, 
                                   micro_prompt_ko, pro_prompt_ko, 
                                   micro_prompt_en, pro_prompt_en):
    """ì˜ì–´ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì´ì¤‘ ì–¸ì–´ ë‹µë³€ ìƒì„± - GitHub ì›ë³¸ ë°©ì‹ ì™„ì „ ì ìš©"""
    
    # ì‘ë‹µì„ ì €ì¥í•  ì»¨í…Œì´ë„ˆ
    response_container = st.empty()
    
    # 1ë‹¨ê³„: í•œêµ­ì–´ ë‹µë³€ ìƒì„± (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë³‘ë ¬ ì‹¤í–‰)
    st.caption("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë‹µë³€ ìƒì„± ì¤‘ (ë‹´ë‹¹ì í™•ì¸ìš©) - GitHub ì›ë³¸ ë°©ì‹ ë³‘ë ¬ ì²˜ë¦¬...")
    
    # Pro ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì €ì¥í•  ë²„í¼ (GitHub ì›ë³¸ê³¼ ë™ì¼)
    korean_pro_buffer = []
    korean_pro_complete = False
    
    def collect_korean_pro_stream():
        """í•œêµ­ì–´ Pro ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ë²„í¼ì— ìˆ˜ì§‘ (GitHub ì›ë³¸ê³¼ ë™ì¼)"""
        nonlocal korean_pro_buffer, korean_pro_complete
        try:
            for chunk in stream_nova_model('amazon.nova-pro-v1:0', pro_prompt_ko, max_tokens=2048, temperature=0.5):
                korean_pro_buffer.append(chunk)
            korean_pro_complete = True
        except Exception as e:
            korean_pro_buffer.append(f"\nâŒ Nova Pro (í•œêµ­ì–´) ì˜¤ë¥˜: {e}")
            korean_pro_complete = True
    
    # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ThreadPoolExecutor ë³‘ë ¬ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=2) as executor:
        # Pro ëª¨ë¸ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ (GitHub ì›ë³¸ê³¼ ë™ì¼)
        future_korean_pro = executor.submit(collect_korean_pro_stream)
        
        # 1ë‹¨ê³„: Nova Micro ìŠ¤íŠ¸ë¦¬ë° (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ì‹¤ì‹œê°„ ì¶œë ¥)
        korean_micro_response = ""
        try:
            for chunk in stream_nova_model('amazon.nova-micro-v1:0', micro_prompt_ko, max_tokens=1024, temperature=0.3):
                korean_micro_response += chunk
                temp_display = f"## ğŸ“‹ í•œêµ­ì–´ ë‹µë³€ (ë‹´ë‹¹ì í™•ì¸ìš©)\n{korean_micro_response}â–Œ"
                response_container.markdown(temp_display)
                time.sleep(0.02)  # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ íƒ€ì´í•‘ íš¨ê³¼
            
            # Micro ì™„ë£Œ í›„ ìµœì¢… í‘œì‹œ (GitHub ì›ë³¸ê³¼ ë™ì¼)
            response_container.markdown(f"## ğŸ“‹ í•œêµ­ì–´ ë‹µë³€ (ë‹´ë‹¹ì í™•ì¸ìš©)\n{korean_micro_response}")
            
        except Exception as e:
            error_msg = f"âŒ Nova Micro (í•œêµ­ì–´) ì˜¤ë¥˜: {e}\n\n"
            korean_micro_response += error_msg
            response_container.markdown(f"## ğŸ“‹ í•œêµ­ì–´ ë‹µë³€ (ë‹´ë‹¹ì í™•ì¸ìš©)\n{korean_micro_response}")
        
        # 2ë‹¨ê³„: Pro ëª¨ë¸ ê²°ê³¼ ì¶œë ¥ (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë²„í¼ ì²˜ë¦¬)
        st.caption("ğŸ” í•œêµ­ì–´ ìƒì„¸ ë¶„ì„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²° ì¤‘...")
        
        buffer_index = 0
        korean_current_display = f"## ğŸ“‹ í•œêµ­ì–´ ë‹µë³€ (ë‹´ë‹¹ì í™•ì¸ìš©)\n{korean_micro_response}\n\n---\n\n**ğŸ” Nova Pro ìƒì„¸ ë¶„ì„:**\n\n"
        
        # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë²„í¼ ì‹¤ì‹œê°„ ì¶œë ¥ ë°©ì‹
        while not korean_pro_complete or buffer_index < len(korean_pro_buffer):
            # ë²„í¼ì— ìƒˆë¡œìš´ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶œë ¥
            while buffer_index < len(korean_pro_buffer):
                chunk = korean_pro_buffer[buffer_index]
                korean_current_display += chunk
                response_container.markdown(korean_current_display + "â–Œ")
                time.sleep(0.01)  # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë¹ ë¥¸ íƒ€ì´í•‘ íš¨ê³¼
                buffer_index += 1
            
            # Pro ëª¨ë¸ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì ì‹œ ëŒ€ê¸° (GitHub ì›ë³¸ê³¼ ë™ì¼)
            if not korean_pro_complete:
                time.sleep(0.05)
        
        # í•œêµ­ì–´ ìµœì¢… í‘œì‹œ (ì»¤ì„œ ì œê±°)
        response_container.markdown(korean_current_display)
        
        # Pro ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (GitHub ì›ë³¸ê³¼ ë™ì¼)
        future_korean_pro.result()
        korean_final = korean_current_display
    
    # 2ë‹¨ê³„: ì˜ì–´ ë‹µë³€ ìƒì„± (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë³‘ë ¬ ì‹¤í–‰)
    st.caption("ğŸ‡ºğŸ‡¸ ì˜ì–´ ë‹µë³€ ìƒì„± ì¤‘ (ê³ ê°ìš©) - GitHub ì›ë³¸ ë°©ì‹ ë³‘ë ¬ ì²˜ë¦¬...")
    
    # Pro ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì €ì¥í•  ë²„í¼ (GitHub ì›ë³¸ê³¼ ë™ì¼)
    english_pro_buffer = []
    english_pro_complete = False
    
    def collect_english_pro_stream():
        """ì˜ì–´ Pro ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ë²„í¼ì— ìˆ˜ì§‘ (GitHub ì›ë³¸ê³¼ ë™ì¼)"""
        nonlocal english_pro_buffer, english_pro_complete
        try:
            for chunk in stream_nova_model('amazon.nova-pro-v1:0', pro_prompt_en, max_tokens=2048, temperature=0.5):
                english_pro_buffer.append(chunk)
            english_pro_complete = True
        except Exception as e:
            english_pro_buffer.append(f"\nâŒ Nova Pro (English) Error: {e}")
            english_pro_complete = True
    
    # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ThreadPoolExecutor ë³‘ë ¬ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=2) as executor:
        # Pro ëª¨ë¸ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ (GitHub ì›ë³¸ê³¼ ë™ì¼)
        future_english_pro = executor.submit(collect_english_pro_stream)
        
        # 1ë‹¨ê³„: Nova Micro ìŠ¤íŠ¸ë¦¬ë° (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ì‹¤ì‹œê°„ ì¶œë ¥)
        english_micro_response = ""
        try:
            for chunk in stream_nova_model('amazon.nova-micro-v1:0', micro_prompt_en, max_tokens=1024, temperature=0.3):
                english_micro_response += chunk
                temp_display = f"""{korean_final}

---

## ğŸŒ English Response (For Customer)
{english_micro_response}â–Œ"""
                response_container.markdown(temp_display)
                time.sleep(0.02)  # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ íƒ€ì´í•‘ íš¨ê³¼
            
            # Micro ì™„ë£Œ í›„ ìµœì¢… í‘œì‹œ (GitHub ì›ë³¸ê³¼ ë™ì¼)
            temp_display = f"""{korean_final}

---

## ğŸŒ English Response (For Customer)
{english_micro_response}"""
            response_container.markdown(temp_display)
            
        except Exception as e:
            error_msg = f"âŒ Nova Micro (English) Error: {e}\n\n"
            english_micro_response += error_msg
            temp_display = f"""{korean_final}

---

## ğŸŒ English Response (For Customer)
{english_micro_response}"""
            response_container.markdown(temp_display)
        
        # 2ë‹¨ê³„: Pro ëª¨ë¸ ê²°ê³¼ ì¶œë ¥ (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë²„í¼ ì²˜ë¦¬)
        st.caption("ğŸ” ì˜ì–´ ìƒì„¸ ë¶„ì„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²° ì¤‘...")
        
        buffer_index = 0
        english_current_display = f"""{korean_final}

---

## ğŸŒ English Response (For Customer)
{english_micro_response}

---

**ğŸ” Nova Pro Detailed Analysis:**

"""
        
        # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë²„í¼ ì‹¤ì‹œê°„ ì¶œë ¥ ë°©ì‹
        while not english_pro_complete or buffer_index < len(english_pro_buffer):
            # ë²„í¼ì— ìƒˆë¡œìš´ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶œë ¥
            while buffer_index < len(english_pro_buffer):
                chunk = english_pro_buffer[buffer_index]
                english_current_display += chunk
                response_container.markdown(english_current_display + "â–Œ")
                time.sleep(0.01)  # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë¹ ë¥¸ íƒ€ì´í•‘ íš¨ê³¼
                buffer_index += 1
            
            # Pro ëª¨ë¸ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì ì‹œ ëŒ€ê¸° (GitHub ì›ë³¸ê³¼ ë™ì¼)
            if not english_pro_complete:
                time.sleep(0.05)
        
        # ìµœì¢… í‘œì‹œ (ì»¤ì„œ ì œê±°)
        response_container.markdown(english_current_display)
        
        # Pro ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (GitHub ì›ë³¸ê³¼ ë™ì¼)
        future_english_pro.result()
        
        return english_current_display

def generate_dual_answer(query, context_docs, conversation_history, user_language="Korean"):
    """ë“€ì–¼ ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„± (ì™„ì „í•œ ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if not context_docs:
        if user_language == "English":
            return "Sorry, I couldn't find relevant documents. Please try searching with different keywords or rephrase your question."
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œê±°ë‚˜ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”."
    
    # ì‚¬ìš©ì ì–¸ì–´ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ìƒì„±
    if user_language == "English":
        # ì˜ì–´ ì‚¬ìš©ì: í•œêµ­ì–´ ë‹µë³€ + ì˜ì–´ ë‹µë³€ ëª¨ë‘ ìƒì„±
        # 1ë‹¨ê³„: í•œêµ­ì–´ë¡œ ë‹µë³€ ìƒì„± (ë‹´ë‹¹ì í™•ì¸ìš©)
        micro_prompt_ko, pro_prompt_ko = create_prompts(query, context_docs, conversation_history, "Korean")
        
        # 2ë‹¨ê³„: ì˜ì–´ë¡œ ë‹µë³€ ìƒì„± (ê³ ê°ìš©)
        micro_prompt_en, pro_prompt_en = create_prompts(query, context_docs, conversation_history, "English")
        
        return generate_dual_language_response(query, context_docs, conversation_history, 
                                             micro_prompt_ko, pro_prompt_ko, 
                                             micro_prompt_en, pro_prompt_en)
    else:
        # í•œêµ­ì–´ ì‚¬ìš©ì: GitHub ì›ë³¸ê³¼ 100% ë™ì¼í•œ ë³‘ë ¬ ì‹¤í–‰
        micro_prompt, pro_prompt = create_prompts(query, context_docs, conversation_history, "Korean")
        
        # ì‘ë‹µì„ ì €ì¥í•  ì»¨í…Œì´ë„ˆ
        response_container = st.empty()
        
        # Pro ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì €ì¥í•  ë²„í¼ (GitHub ì›ë³¸ê³¼ ë™ì¼)
        pro_buffer = []
        pro_complete = False
        
        def collect_pro_stream():
            """Pro ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ë²„í¼ì— ìˆ˜ì§‘ (GitHub ì›ë³¸ê³¼ ë™ì¼)"""
            nonlocal pro_buffer, pro_complete
            try:
                for chunk in stream_nova_model('amazon.nova-pro-v1:0', pro_prompt, max_tokens=2048, temperature=0.5):
                    pro_buffer.append(chunk)
                pro_complete = True
            except Exception as e:
                pro_buffer.append(f"\nâŒ Nova Pro ì˜¤ë¥˜: {e}")
                pro_complete = True
        
        # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ThreadPoolExecutor ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=2) as executor:
            st.caption("ğŸš€ GitHub ì›ë³¸ ë°©ì‹: Nova Micro + Pro ë³‘ë ¬ ì‹¤í–‰...")
            
            # Pro ëª¨ë¸ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ (GitHub ì›ë³¸ê³¼ ë™ì¼)
            future_pro = executor.submit(collect_pro_stream)
            
            # 1ë‹¨ê³„: Nova Micro ìŠ¤íŠ¸ë¦¬ë° (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ì‹¤ì‹œê°„ ì¶œë ¥)
            full_micro_response = ""
            try:
                for chunk in stream_nova_model('amazon.nova-micro-v1:0', micro_prompt, max_tokens=1024, temperature=0.3):
                    full_micro_response += chunk
                    response_container.markdown(full_micro_response + "â–Œ")
                    time.sleep(0.02)  # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ íƒ€ì´í•‘ íš¨ê³¼
                
                # Micro ì™„ë£Œ í›„ ìµœì¢… í‘œì‹œ (GitHub ì›ë³¸ê³¼ ë™ì¼)
                response_container.markdown(full_micro_response)
                
            except Exception as e:
                error_msg = f"âŒ Nova Micro ì˜¤ë¥˜: {e}\n\n"
                full_micro_response += error_msg
                response_container.markdown(full_micro_response)
            
            # 2ë‹¨ê³„: Pro ëª¨ë¸ ê²°ê³¼ ì¶œë ¥ (GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë²„í¼ ì²˜ë¦¬)
            st.caption("ğŸ” Nova Pro ìƒì„¸ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²° ì¤‘...")
            
            buffer_index = 0
            current_display = full_micro_response + "\n\n---\n\n**ğŸ” Nova Pro ìƒì„¸ ë¶„ì„:**\n\n"
            
            # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë²„í¼ ì‹¤ì‹œê°„ ì¶œë ¥ ë°©ì‹
            while not pro_complete or buffer_index < len(pro_buffer):
                # ë²„í¼ì— ìƒˆë¡œìš´ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶œë ¥
                while buffer_index < len(pro_buffer):
                    chunk = pro_buffer[buffer_index]
                    current_display += chunk
                    response_container.markdown(current_display + "â–Œ")
                    time.sleep(0.01)  # GitHub ì›ë³¸ê³¼ ë™ì¼í•œ ë¹ ë¥¸ íƒ€ì´í•‘ íš¨ê³¼
                    buffer_index += 1
                
                # Pro ëª¨ë¸ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì ì‹œ ëŒ€ê¸° (GitHub ì›ë³¸ê³¼ ë™ì¼)
                if not pro_complete:
                    time.sleep(0.05)
            
            # ìµœì¢… í‘œì‹œ (ì»¤ì„œ ì œê±°)
            response_container.markdown(current_display)
            
            # Pro ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (GitHub ì›ë³¸ê³¼ ë™ì¼)
            future_pro.result()
            
            return current_display

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸŒ ê¸€ë¡œë²Œ CS ì„¤ì •")
    
    # ì–¸ì–´ ì„ íƒ
    user_language = st.selectbox(
        "ğŸŒ ì–¸ì–´ ì„ íƒ / Language",
        ["í•œêµ­ì–´ (Korean)", "English"],
        index=0
    )
    
    # ì–¸ì–´ ì½”ë“œ ì¶”ì¶œ
    language_code = "Korean" if "Korean" in user_language else "English"
    
    st.divider()
    
    # ë²ˆì—­ ê¸°ëŠ¥
    st.subheader("ğŸ”„ ì‹¤ì‹œê°„ ë²ˆì—­")
    
    translation_input = st.text_area(
        "ë²ˆì—­í•  í…ìŠ¤íŠ¸ ì…ë ¥ / Enter text to translate:",
        placeholder="ê²Œì„ ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”... / Enter gaming-related text...",
        height=100
    )
    
    if st.button("ğŸ”„ ë²ˆì—­í•˜ê¸° / Translate"):
        if translation_input.strip():
            with st.spinner("ë²ˆì—­ ì¤‘... / Translating..."):
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ì— ë”°ë¼ ë²ˆì—­ ë°©í–¥ ê²°ì •
                if language_code == "English":
                    # ì˜ì–´ UI ì„ íƒ ì‹œ: í•œêµ­ì–´ â†’ ì˜ì–´ë¡œ ë²ˆì—­
                    translation_result = translate_text_with_caching(translation_input, "English")
                else:
                    # í•œêµ­ì–´ UI ì„ íƒ ì‹œ: ì˜ì–´ â†’ í•œêµ­ì–´ë¡œ ë²ˆì—­
                    translation_result = translate_text_with_caching(translation_input, "Korean")
                
                st.success("âœ… ë²ˆì—­ ì™„ë£Œ / Translation Complete")
                
                # ë²ˆì—­ ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**ì›ë¬¸ ({translation_result['detected_language']}):**")
                    st.info(translation_result['original_text'])
                
                with col2:
                    st.markdown(f"**ë²ˆì—­ ({translation_result['target_language']}):**")
                    st.success(translation_result['translated_text'])
        else:
            st.warning("ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. / Please enter text to translate.")
    
    st.divider()
    
    # í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    st.header("ğŸ“Š í† í° ì‚¬ìš©ëŸ‰")
    
    try:
        # ìµœê·¼ 1ì‹œê°„ Nova Pro í† í° ì‚¬ìš©ëŸ‰
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=1)
        
        response = boto3.client('cloudwatch', region_name='us-east-1').get_metric_statistics(
            Namespace='AWS/Bedrock',
            MetricName='InputTokenCount',
            Dimensions=[{'Name': 'ModelId', 'Value': 'amazon.nova-pro-v1:0'}],
            StartTime=start_time,
            EndTime=end_time,
            Period=3600,
            Statistics=['Sum']
        )
        
        if response['Datapoints']:
            input_tokens = int(response['Datapoints'][0]['Sum'])
            st.metric("Nova Pro ì…ë ¥ í† í° (1ì‹œê°„)", f"{input_tokens:,}")
        else:
            st.info("í† í° ì‚¬ìš©ëŸ‰ ë°ì´í„° ì—†ìŒ")
            
        # ìºì‹œ íš¨ìœ¨ì„± í™•ì¸
        cache_response = boto3.client('cloudwatch', region_name='us-east-1').get_metric_statistics(
            Namespace='AWS/Bedrock',
            MetricName='CacheReadInputTokenCount',
            Dimensions=[{'Name': 'ModelId', 'Value': 'amazon.nova-pro-v1:0'}],
            StartTime=start_time,
            EndTime=end_time,
            Period=3600,
            Statistics=['Sum']
        )
        
        if cache_response['Datapoints']:
            cache_tokens = int(cache_response['Datapoints'][0]['Sum'])
            if input_tokens > 0:
                cache_efficiency = (cache_tokens / input_tokens) * 100
                st.metric("ìºì‹œ íš¨ìœ¨", f"{cache_efficiency:.1f}%", f"{cache_tokens:,} í† í° ì ˆì•½")
            else:
                st.metric("ìºì‹œ í† í°", f"{cache_tokens:,}")
        else:
            st.info("ìºì‹œ ë°ì´í„° ì—†ìŒ")
            
    except Exception as e:
        st.error(f"í† í° ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)[:50]}...")

    # ì‹œìŠ¤í…œ ìƒíƒœ
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # Knowledge Base ìƒíƒœ í™•ì¸
    try:
        bedrock_agent_client = boto3.client('bedrock-agent-runtime', region_name='us-east-1')
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ Knowledge Base ìƒíƒœ í™•ì¸
        test_response = bedrock_agent_client.retrieve(
            knowledgeBaseId='SJJP9YYPHX',
            retrievalQuery={'text': 'test'},
            retrievalConfiguration={'vectorSearchConfiguration': {'numberOfResults': 1}}
        )
        st.success("âœ… Knowledge Base ì—°ê²°ë¨")
        st.caption(f"Knowledge Base ID: SJJP9YYPHX")
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ í‘œì‹œ
        result_count = len(test_response.get('retrievalResults', []))
        if result_count > 0:
            st.info(f"ğŸ“š Knowledge Base ì‘ë‹µ ê°€ëŠ¥")
        else:
            st.warning("âš ï¸ Knowledge Baseì— ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
    except Exception as e:
        st.error("âŒ Knowledge Base ì—°ê²° ì‹¤íŒ¨")
        st.caption(f"ì˜¤ë¥˜: {str(e)[:100]}...")
    
    st.divider()
    st.subheader("ğŸ¤– AI ëª¨ë¸ ì •ë³´")
    st.info("**Nova Micro + Nova Pro + Translation**")
    st.caption("â€¢ âš¡ Nova Micro: ì¦‰ê°ì ì¸ ì´ˆê¸° ì‘ë‹µ")
    st.caption("â€¢ ğŸ§  Nova Pro: ìƒì„¸í•œ ìµœì¢… ë‹µë³€")
    st.caption("â€¢ ğŸŒ Nova Pro: ê³ í’ˆì§ˆ ê²Œì„ ìš©ì–´ ë²ˆì—­")
    st.caption("â€¢ ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì‘ë‹µ")
    st.caption("â€¢ ğŸ“¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°")
    st.caption("â€¢ ğŸ’° í”„ë¡¬í”„íŠ¸ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆì•½")
    
    st.divider()
    st.subheader("ğŸ’¡ ì‚¬ìš© íŒ")
    if language_code == "English":
        st.markdown("""
        - **Keyword Search**: "Amazon Survival", "CS Response" etc.
        - **Specific Questions**: "How to fix game execution error?"
        - **Complex Questions**: "Amazon Survival characters and worldview"
        - **Development Related**: "Local server setup", "Dev environment"
        - References previous conversations
        - **New Features**: Quick initial response + Detailed final answer
        - **Translation**: Real-time gaming terminology translation
        """)
    else:
        st.markdown("""
        - **í‚¤ì›Œë“œ ê²€ìƒ‰**: "ì•„ë§ˆì¡´ ìƒì¡´ê¸°", "CS ë‹µë³€" ë“±
        - **êµ¬ì²´ì  ì§ˆë¬¸**: "ê²Œì„ ì‹¤í–‰ ì˜¤ë¥˜ í•´ê²° ë°©ë²•ì€?"
        - **ë³µí•© ì§ˆë¬¸**: "ì•„ë§ˆì¡´ ìƒì¡´ê¸° ë“±ì¥ì¸ë¬¼ê³¼ ì„¸ê³„ê´€"
        - **ê°œë°œ ê´€ë ¨**: "ë¡œì»¬ì„œë²„ ì„¤ì •", "ê°œë°œ í™˜ê²½"
        - ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•©ë‹ˆë‹¤
        - **ìƒˆë¡œìš´ ê¸°ëŠ¥**: ë¹ ë¥¸ ì´ˆê¸° ì‘ë‹µ + ìƒì„¸í•œ ìµœì¢… ë‹µë³€
        - **ë²ˆì—­ ê¸°ëŠ¥**: ì‹¤ì‹œê°„ ê²Œì„ ìš©ì–´ ë²ˆì—­
        """)
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ / Clear Chat"):
        st.session_state.messages = []
        st.rerun()

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

if not st.session_state.messages:
    with st.chat_message("assistant"):
        if language_code == "English":
            st.markdown("""
            Hello! I'm the Global CS Chatbot. ğŸŒ
            
            **Upgraded with Nova Micro + Nova Pro + Translation** for faster and more accurate responses!
            
            âš¡ **Nova Micro**: Instant initial response within 1 second  
            ğŸ§  **Nova Pro**: Detailed final response generated in background  
            ğŸŒ **Translation**: Real-time gaming terminology translation  
            ğŸ”„ **Parallel Processing**: Both models work simultaneously to minimize latency
            
            I can answer questions based on **36 documents** and provide real-time translation for gaming terminology.
            Feel free to ask me anything!
            
            **Example Questions:**
            - "Tell me about Amazon Survival in detail"
            - "What are the CS response formats and guidelines?"
            - "How to solve game execution problems?"
            - "Please explain local server setup step by step"
            - "What are the characteristics of Amazon Survival characters?"
            """)
        else:
            st.markdown("""
            ì•ˆë…•í•˜ì„¸ìš”! ê¸€ë¡œë²Œ CS ì±—ë´‡ì…ë‹ˆë‹¤. ğŸŒ
            
            **Nova Micro + Nova Pro + Translation**ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œë˜ì–´ ë”ìš± ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤!
            
            âš¡ **Nova Micro**: 1ì´ˆ ì´ë‚´ ì¦‰ê°ì ì¸ ì´ˆê¸° ì‘ë‹µ  
            ğŸ§  **Nova Pro**: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìƒì„¸í•œ ìµœì¢… ë‹µë³€ ìƒì„±  
            ğŸŒ **ë²ˆì—­ ê¸°ëŠ¥**: ì‹¤ì‹œê°„ ê²Œì„ ìš©ì–´ ë²ˆì—­  
            ğŸ”„ **ë³‘ë ¬ ì²˜ë¦¬**: ë‘ ëª¨ë¸ì´ ë™ì‹œì— ì‘ì—…í•˜ì—¬ ì§€ì—° ì‹œê°„ ìµœì†Œí™”
            
            **36ê°œì˜ ë¬¸ì„œ**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , ê²Œì„ ìš©ì–´ ì‹¤ì‹œê°„ ë²ˆì—­ì„ ì œê³µí•©ë‹ˆë‹¤.
            ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!
            
            **ì˜ˆì‹œ ì§ˆë¬¸:**
            - "ì•„ë§ˆì¡´ ìƒì¡´ê¸°ì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”"
            - "CS ë‹µë³€ í˜•ì‹ê³¼ ê°€ì´ë“œë¼ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            - "ê²Œì„ ì‹¤í–‰ ê´€ë ¨ ë¬¸ì œ í•´ê²° ë°©ë²•ì€?"
            - "ë¡œì»¬ì„œë²„ ì„¤ì • ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”"
            - "ì•„ë§ˆì¡´ ìƒì¡´ê¸° ë“±ì¥ì¸ë¬¼ë“¤ì˜ íŠ¹ì§•ì€?"
            """)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and "references" in message:
            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ / Reference Documents"):
                for doc in message["references"]:
                    st.markdown(f"**{doc['title']}** (ì ìˆ˜: {doc.get('score', 0)})")
                    if 'matched_keywords' in doc and doc['matched_keywords']:
                        st.caption(f"ğŸ” ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {', '.join(doc['matched_keywords'])}")
                    st.markdown(doc['content'][:600] + ("..." if len(doc['content']) > 600 else ""))
                    if doc['url'] != '#':
                        st.markdown(f"[ì›ë³¸ ë³´ê¸°]({doc['url']})")
                    st.divider()

# ì±„íŒ… ì…ë ¥
if language_code == "English":
    prompt_placeholder = "Enter your question..."
else:
    prompt_placeholder = "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."

if prompt := st.chat_input(prompt_placeholder):
    # ë²ˆì—­ ê¸°ëŠ¥ ì¶”ê°€ - ì‚¬ìš©ì ì…ë ¥ì´ ë‹¤ë¥¸ ì–¸ì–´ì¸ ê²½ìš° ë²ˆì—­
    original_prompt = prompt
    detected_language = "Korean" if re.search(r'[ê°€-í£]', prompt) else "English"
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ì™€ ì…ë ¥ ì–¸ì–´ê°€ ë‹¤ë¥¸ ê²½ìš° ë²ˆì—­
    if (language_code == "Korean" and detected_language == "English") or \
       (language_code == "English" and detected_language == "Korean"):
        
        with st.spinner("Nova Proê°€ ì§ˆë¬¸ì„ ë²ˆì—­ ì¤‘... / Nova Pro is translating question..."):
            translation_result = translate_text_with_caching(prompt, language_code)
            translated_prompt = translation_result['translated_text']
            
            # ë²ˆì—­ëœ ì§ˆë¬¸ í‘œì‹œ
            st.info(f"ğŸ”„ ë²ˆì—­ëœ ì§ˆë¬¸ / Translated Question: {translated_prompt}")
            prompt = translated_prompt
    
    st.session_state.messages.append({"role": "user", "content": original_prompt})
    with st.chat_message("user"):
        st.markdown(original_prompt)

    with st.chat_message("assistant"):
        # Knowledge Baseì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
        context_docs = search_knowledge_base(prompt)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
        if context_docs:
            if language_code == "English":
                st.caption(f"ğŸ” Found {len(context_docs)} documents from Knowledge Base")
            else:
                st.caption(f"ğŸ” Knowledge Baseì—ì„œ {len(context_docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
        else:
            if language_code == "English":
                st.caption("ğŸ” No documents found in Knowledge Base")
            else:
                st.caption("ğŸ” Knowledge Baseì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ")
            
        # ë“€ì–¼ ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
        answer = generate_dual_answer(prompt, context_docs, st.session_state.messages, language_code)
        
        if context_docs:
            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ / Reference Documents"):
                for doc in context_docs:
                    st.markdown(f"**{doc['title']}** (ì ìˆ˜: {doc.get('score', 0):.3f})")
                    st.markdown(doc['content'][:600] + ("..." if len(doc['content']) > 600 else ""))
                    if doc['url'] != '#':
                        st.markdown(f"[ì›ë³¸ ë³´ê¸°]({doc['url']})")
                    st.divider()
            
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer,
                "references": context_docs
            })
        else:
            st.session_state.messages.append({"role": "assistant", "content": answer})

st.divider()
if language_code == "English":
    st.caption("ğŸ”„ Knowledge Base provides real-time intelligent search.")
    st.caption("âš¡ Provides fast and accurate responses with Nova Micro + Nova Pro dual model.")
    st.caption("ğŸŒ Real-time gaming terminology translation available.")
    st.caption("ğŸ“š Powered by Amazon Bedrock Knowledge Base.")
else:
    st.caption("ğŸ”„ Knowledge Baseê°€ ì‹¤ì‹œê°„ ì§€ëŠ¥í˜• ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.")
    st.caption("âš¡ Nova Micro + Nova Pro ë“€ì–¼ ëª¨ë¸ë¡œ ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")
    st.caption("ğŸŒ ì‹¤ì‹œê°„ ê²Œì„ ìš©ì–´ ë²ˆì—­ì„ ì§€ì›í•©ë‹ˆë‹¤.")
    st.caption("ğŸ“š Amazon Bedrock Knowledge Baseë¡œ êµ¬ë™ë©ë‹ˆë‹¤.")
