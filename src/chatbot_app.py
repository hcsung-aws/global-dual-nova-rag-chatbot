import streamlit as st
import boto3
import json
import os
import re
import time
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from botocore.config import Config

# GlossaryManager import ì¶”ê°€
from src.utils.glossary_manager import get_glossary_manager

# AWSClientManager import ì¶”ê°€
from src.core.aws_clients import get_aws_client_manager

# PromptFactory import ì¶”ê°€
from src.core.prompt_generator import PromptFactory

# StreamingHandler import ì¶”ê°€
from src.core.streaming_handler import StreamingHandler

# DualResponseGenerator import ì¶”ê°€
from src.core.dual_response import DualResponseGenerator

# TranslationService import ì¶”ê°€
from src.services.translation_service import TranslationService

# KnowledgeBaseService import ì¶”ê°€
from src.services.knowledge_base_service import KnowledgeBaseService

# BedrockService import ì¶”ê°€
from src.services.bedrock_service import BedrockService

# ë²„ì „ ì •ë³´
VERSION = "0.1.0"

st.set_page_config(page_title=f'ê¸€ë¡œë²Œ CS ì±—ë´‡ v{VERSION} ğŸŒ', page_icon='ğŸŒ', layout='wide')

st.markdown(f'''
<div style="text-align: center; padding: 1rem 0; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 2rem;">
    <h1>ğŸŒ ê¸€ë¡œë²Œ CS ì±—ë´‡ <span style="font-size: 0.6em; opacity: 0.8;">v{VERSION}</span></h1>
    <p>ë‹¤êµ­ì–´ ì§€ì› ê³ ê° ì„œë¹„ìŠ¤ (Powered by Nova Micro + Nova Pro + Translation)</p>
</div>
''', unsafe_allow_html=True)

# AWSClientManagerë¥¼ ì‚¬ìš©í•œ í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
@st.cache_resource
def get_aws_clients():
    """
    AWSClientManagerë¥¼ ì‚¬ìš©í•œ AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ AWSClientManagerì˜ ì´ì ì„ í™œìš©
    """
    print("Running get_aws_clients().")
    try:
        manager = get_aws_client_manager()
        clients = manager.initialize_clients(['s3', 'bedrock-runtime', 'secretsmanager'])
        
        # ì¤‘ìš”í•œ í´ë¼ì´ì–¸íŠ¸ ê²€ì¦ - ë” ìƒì„¸í•œ ë¡œê¹…
        if 'bedrock-runtime' not in clients or clients.get('bedrock-runtime') is None:
            print("âŒ Bedrock Runtime í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í´ë¼ì´ì–¸íŠ¸: {list(clients.keys())}")
            
            # ì§ì ‘ ìƒì„± ì‹œë„
            try:
                print("ğŸ”„ Bedrock Runtime í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ìƒì„± ì‹œë„...")
                import boto3
                from botocore.config import Config
                
                config = Config(
                    read_timeout=60,
                    connect_timeout=10,
                    retries={'max_attempts': 3, 'mode': 'adaptive'}
                )
                
                bedrock_client = boto3.client(
                    'bedrock-runtime',
                    region_name='us-east-1',
                    config=config
                )
                
                # bedrock-runtime í´ë¼ì´ì–¸íŠ¸ í—¬ìŠ¤ì²´í¬ (invoke_model ë©”ì„œë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸)
                if not hasattr(bedrock_client, 'invoke_model'):
                    raise AttributeError("bedrock-runtime í´ë¼ì´ì–¸íŠ¸ì— invoke_model ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                clients['bedrock-runtime'] = bedrock_client
                print("âœ… Bedrock Runtime í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ìƒì„± ì„±ê³µ")
                
            except Exception as direct_error:
                print(f"âŒ ì§ì ‘ ìƒì„±ë„ ì‹¤íŒ¨: {direct_error}")
                st.error(f"âŒ Bedrock Runtime í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {direct_error}")
                st.stop()
        
        print(f"âœ… AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {list(clients.keys())}")
        return clients
        
    except Exception as e:
        print(f"âŒ AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.error(f"âŒ AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
aws_manager = get_aws_client_manager()
clients = get_aws_clients()

# StreamingHandler ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
try:
    streaming_handler = StreamingHandler(clients)
    print("âœ… StreamingHandler ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    st.error(f"âŒ StreamingHandler ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    st.write("**ë””ë²„ê¹… ì •ë³´:**")
    st.write(f"- ì‚¬ìš© ê°€ëŠ¥í•œ í´ë¼ì´ì–¸íŠ¸: {list(clients.keys())}")
    st.write(f"- bedrock-runtime í´ë¼ì´ì–¸íŠ¸: {clients.get('bedrock-runtime', 'None')}")
    st.stop()

# TranslationService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
translation_service = TranslationService(aws_manager)

# KnowledgeBaseService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
knowledge_base_service = KnowledgeBaseService(aws_manager)

# BedrockService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (StreamingHandlerì™€ í†µí•©)
bedrock_service = BedrockService(aws_manager, streaming_handler)

# DualResponseGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
dual_response_generator = DualResponseGenerator(streaming_handler)

# ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ ê´€ë¦¬ (GlossaryManager ì‚¬ìš©)
def get_game_glossary():
    """ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (GlossaryManagerë¥¼ í†µí•œ ì¤‘ì•™í™”ëœ ê´€ë¦¬)"""
    
    try:
        # GlossaryManagerë¥¼ í†µí•´ ë‹¨ì–´ì¥ ë¡œë“œ
        glossary_manager = get_glossary_manager()
        glossary = glossary_manager.get_formatted_glossary()
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        print(f"=== GlossaryManager ë‹¨ì–´ì¥ ë¡œë“œ ===")
        print(f"ë‹¨ì–´ì¥ í¬ê¸°: {len(glossary)} ë¬¸ì")
        print(f"Paul í¬í•¨ ì—¬ë¶€: {'Paul' in glossary}")
        print(f"Hogan í¬í•¨ ì—¬ë¶€: {'Hogan' in glossary}")
        print(f"Manuel í¬í•¨ ì—¬ë¶€: {'Manuel' in glossary}")
        print(f"Agent C í¬í•¨ ì—¬ë¶€: {'Agent C' in glossary}")
        print("=" * 35)
        
        return glossary
        
    except Exception as e:
        print(f"GlossaryManager ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œì—ë„ ê¸°ë³¸ ë‹¨ì–´ì¥ ì œê³µ (ì•ˆì •ì„± ë³´ì¥)
        return "# ê²Œì„ ìš©ì–´ ë‹¨ì–´ì¥ ë¡œë“œ ì˜¤ë¥˜\nê¸°ë³¸ ë‹¨ì–´ì¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."

# ë²ˆì—­ ê´€ë ¨ í•¨ìˆ˜ë“¤
def create_translation_prompt_prefix():
    """ë²ˆì—­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ prefix ìƒì„± (ìºì‹±ìš©)
    
    PromptFactoryë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ê¸°ì¡´ í•˜ë“œì½”ë”©ëœ ë¡œì§ì„ í†µí•© ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´í–ˆìŠµë‹ˆë‹¤.
    """
    return PromptFactory.create_translation_prompt()

def log_token_usage(model_id, response_body, operation="chat"):
    """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… í•¨ìˆ˜"""
    try:
        usage = response_body.get('usage', {})
        input_tokens = usage.get('inputTokens', 0)
        output_tokens = usage.get('outputTokens', 0)
        total_tokens = usage.get('totalTokens', 0)
        cache_read_tokens = usage.get('cacheReadInputTokenCount', 0)
        cache_write_tokens = usage.get('cacheWriteInputTokenCount', 0)
        
        # ë¡œê·¸ ì¶œë ¥
        print(f"=== í† í° ì‚¬ìš©ëŸ‰ ({operation}) ===")
        print(f"ëª¨ë¸: {model_id}")
        print(f"ì…ë ¥ í† í°: {input_tokens:,}")
        print(f"ì¶œë ¥ í† í°: {output_tokens:,}")
        print(f"ì´ í† í°: {total_tokens:,}")
        print(f"ìºì‹œ ì½ê¸° í† í°: {cache_read_tokens:,}")
        print(f"ìºì‹œ ì“°ê¸° í† í°: {cache_write_tokens:,}")
        
        # ìºì‹± íš¨ê³¼ ê³„ì‚°
        if cache_read_tokens > 0:
            cache_efficiency = (cache_read_tokens / input_tokens) * 100 if input_tokens > 0 else 0
            print(f"ìºì‹± íš¨ìœ¨: {cache_efficiency:.1f}%")
            
            # Streamlitì— ìºì‹± íš¨ê³¼ í‘œì‹œ
            st.sidebar.success(f"ğŸš€ ìºì‹œ íš¨ìœ¨: {cache_efficiency:.1f}% ({cache_read_tokens:,} í† í° ì ˆì•½)")
        
        print("=" * 40)
        
    except Exception as e:
        print(f"í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ì˜¤ë¥˜: {e}")

def translate_text_with_caching(text, target_language="auto"):
    """Nova Proë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ í•¨ìˆ˜ (TranslationServiceë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ TranslationServiceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return translation_service.translate_text_with_caching(text, target_language)



def extract_keywords(query):
    """ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (KnowledgeBaseServiceë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ KnowledgeBaseServiceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return knowledge_base_service._extract_keywords(query)

def search_knowledge_base(query, max_results=5):
    """Bedrock Knowledge Baseì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ (KnowledgeBaseServiceë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ KnowledgeBaseServiceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return knowledge_base_service.search_knowledge_base(query, max_results)

def create_answer_prompt_prefix(user_language="Korean"):
    """ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ prefix ìƒì„± (ìºì‹±ìš©)
    
    PromptFactoryë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ê¸°ì¡´ í•˜ë“œì½”ë”©ëœ ë¡œì§ì„ í†µí•© ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´í–ˆìŠµë‹ˆë‹¤.
    
    Args:
        user_language: ì‚¬ìš©ì ì–¸ì–´ ("Korean" ë˜ëŠ” "English")
        
    Returns:
        str: ë‹µë³€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸
    """
    # ë‹¨ì–´ì¥ ë¡œë“œ ìƒíƒœ ë””ë²„ê¹… (ê¸°ì¡´ ë””ë²„ê¹… ë¡œì§ ìœ ì§€)
    glossary = get_game_glossary()  # ë””ë²„ê¹…ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
    print(f"=== ë‹µë³€ í”„ë¡¬í”„íŠ¸ ìƒì„± ë””ë²„ê¹… ===")
    print(f"ì–¸ì–´: {user_language}")
    print(f"ë‹¨ì–´ì¥ í¬ê¸°: {len(glossary)} ë¬¸ì")
    print(f"Paul í¬í•¨: {'Paul' in glossary}")
    print(f"Hogan í¬í•¨: {'Hogan' in glossary}")
    print(f"Manuel í¬í•¨: {'Manuel' in glossary}")
    print(f"Agent C í¬í•¨: {'Agent C' in glossary}")
    print("=" * 40)
    
    return PromptFactory.create_answer_prompt(user_language=user_language)

def create_prompts(user_query, context_docs, conversation_history, user_language="Korean"):
    """ê° ëª¨ë¸ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„± (DualResponseGeneratorë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ DualResponseGeneratorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return dual_response_generator.create_prompts(user_query, context_docs, conversation_history, user_language)

def stream_nova_model(model_id, prompt, max_tokens=500, temperature=0.3):
    """Nova ëª¨ë¸ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (BedrockServiceë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ BedrockServiceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return bedrock_service.stream_nova_model(model_id, prompt, max_tokens, temperature)

def generate_dual_language_response(query, context_docs, conversation_history, 
                                   micro_prompt_ko, pro_prompt_ko, 
                                   micro_prompt_en, pro_prompt_en):
    """ì˜ì–´ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì´ì¤‘ ì–¸ì–´ ë‹µë³€ ìƒì„± (DualResponseGeneratorë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ DualResponseGeneratorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return dual_response_generator.generate_dual_language_response(
        query, context_docs, conversation_history, 
        micro_prompt_ko, pro_prompt_ko, 
        micro_prompt_en, pro_prompt_en
    )

def generate_dual_answer(query, context_docs, conversation_history, user_language="Korean"):
    """ë“€ì–¼ ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„± (DualResponseGeneratorë¡œ í†µí•©)
    
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ DualResponseGeneratorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return dual_response_generator.generate_dual_answer(query, context_docs, conversation_history, user_language)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸŒ ê¸€ë¡œë²Œ CS ì„¤ì •")
    
    # ì–¸ì–´ ì„ íƒ
    user_language = st.selectbox(
        "ğŸŒ ì–¸ì–´ ì„ íƒ / Language",
        ["í•œêµ­ì–´ (Korean)", "English"],
        index=0
    )
    
    # ì–¸ì–´ ì½”ë“œ ì¶”ì¶œ
    language_code = "Korean" if "Korean" in user_language else "English"
    
    st.divider()
    
    # ë²ˆì—­ ê¸°ëŠ¥
    st.subheader("ğŸ”„ ì‹¤ì‹œê°„ ë²ˆì—­")
    
    translation_input = st.text_area(
        "ë²ˆì—­í•  í…ìŠ¤íŠ¸ ì…ë ¥ / Enter text to translate:",
        placeholder="ê²Œì„ ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”... / Enter gaming-related text...",
        height=100
    )
    
    if st.button("ğŸ”„ ë²ˆì—­í•˜ê¸° / Translate"):
        if translation_input.strip():
            with st.spinner("ë²ˆì—­ ì¤‘... / Translating..."):
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ì— ë”°ë¼ ë²ˆì—­ ë°©í–¥ ê²°ì •
                if language_code == "English":
                    # ì˜ì–´ UI ì„ íƒ ì‹œ: í•œêµ­ì–´ â†’ ì˜ì–´ë¡œ ë²ˆì—­
                    translation_result = translate_text_with_caching(translation_input, "English")
                else:
                    # í•œêµ­ì–´ UI ì„ íƒ ì‹œ: ì˜ì–´ â†’ í•œêµ­ì–´ë¡œ ë²ˆì—­
                    translation_result = translate_text_with_caching(translation_input, "Korean")
                
                st.success("âœ… ë²ˆì—­ ì™„ë£Œ / Translation Complete")
                
                # ë²ˆì—­ ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**ì›ë¬¸ ({translation_result['detected_language']}):**")
                    st.info(translation_result['original_text'])
                
                with col2:
                    st.markdown(f"**ë²ˆì—­ ({translation_result['target_language']}):**")
                    st.success(translation_result['translated_text'])
        else:
            st.warning("ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. / Please enter text to translate.")
    
    st.divider()
    
    # í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    st.header("ğŸ“Š í† í° ì‚¬ìš©ëŸ‰")
    
    try:
        # ìµœê·¼ 1ì‹œê°„ í† í° ì‚¬ìš©ëŸ‰ ì¡°íšŒ
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=1)
        
        # CloudWatch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
        cloudwatch_client = None
        try:
            cloudwatch_client = aws_manager.get_client('cloudwatch', region_name='us-east-1')
        except Exception as init_error:
            st.error(f"CloudWatch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(init_error)}")
            st.caption("CloudWatch ë©”íŠ¸ë¦­ ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            cloudwatch_client = None
        
        # CloudWatch í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ê²½ìš°ì—ë§Œ ë©”íŠ¸ë¦­ ì¡°íšŒ
        if cloudwatch_client is not None:
            # í† í° ì‚¬ìš©ëŸ‰ ì¡°íšŒ í•¨ìˆ˜
            def get_token_metrics(model_id, metric_name, label):
                try:
                    response = cloudwatch_client.get_metric_statistics(
                        Namespace='AWS/Bedrock',
                        MetricName=metric_name,
                        Dimensions=[{'Name': 'ModelId', 'Value': model_id}],
                        StartTime=start_time,
                        EndTime=end_time,
                        Period=3600,
                        Statistics=['Sum']
                    )
                    
                    if response['Datapoints']:
                        tokens = int(response['Datapoints'][0]['Sum'])
                        st.metric(label, f"{tokens:,}")
                        return tokens
                    else:
                        st.info(f"{label}: ë°ì´í„° ì—†ìŒ")
                        return 0
                except Exception as e:
                    st.warning(f"{label} ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:50]}...")
                    return 0
            
            # Nova Pro ë©”íŠ¸ë¦­
            st.subheader("ğŸ§  Nova Pro")
            pro_input = get_token_metrics('amazon.nova-pro-v1:0', 'InputTokenCount', 'Pro ì…ë ¥ í† í°')
            pro_output = get_token_metrics('amazon.nova-pro-v1:0', 'OutputTokenCount', 'Pro ì¶œë ¥ í† í°')
            
            # Nova Micro ë©”íŠ¸ë¦­
            st.subheader("âš¡ Nova Micro")
            micro_input = get_token_metrics('amazon.nova-micro-v1:0', 'InputTokenCount', 'Micro ì…ë ¥ í† í°')
            micro_output = get_token_metrics('amazon.nova-micro-v1:0', 'OutputTokenCount', 'Micro ì¶œë ¥ í† í°')
                
            # ìºì‹œ íš¨ìœ¨ì„± í™•ì¸ (Nova Pro)
            st.subheader("ğŸš€ ìºì‹œ íš¨ìœ¨ì„±")
            try:
                cache_read_response = cloudwatch_client.get_metric_statistics(
                    Namespace='AWS/Bedrock',
                    MetricName='CacheReadInputTokenCount',
                    Dimensions=[{'Name': 'ModelId', 'Value': 'amazon.nova-pro-v1:0'}],
                    StartTime=start_time,
                    EndTime=end_time,
                    Period=3600,
                    Statistics=['Sum']
                )
                
                if cache_read_response['Datapoints']:
                    cache_read_tokens = int(cache_read_response['Datapoints'][0]['Sum'])
                    if pro_input > 0:
                        cache_efficiency = (cache_read_tokens / pro_input) * 100
                        st.metric("Pro ìºì‹œ íš¨ìœ¨", f"{cache_efficiency:.1f}%", f"{cache_read_tokens:,} í† í° ì ˆì•½")
                    else:
                        st.metric("Pro ìºì‹œ ì½ê¸°", f"{cache_read_tokens:,}")
                else:
                    st.info("Pro ìºì‹œ ë°ì´í„° ì—†ìŒ")
            except Exception as e:
                st.warning(f"Pro ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:50]}...")
                
            # ì´ ì‚¬ìš©ëŸ‰ í‘œì‹œ
            total_input = pro_input + micro_input
            total_output = pro_output + micro_output
            if total_input > 0 or total_output > 0:
                st.subheader("ğŸ“Š ì´ ì‚¬ìš©ëŸ‰ (1ì‹œê°„)")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ì´ ì…ë ¥ í† í°", f"{total_input:,}")
                with col2:
                    st.metric("ì´ ì¶œë ¥ í† í°", f"{total_output:,}")
            
    except Exception as e:
        st.error(f"í† í° ëª¨ë‹ˆí„°ë§ ì „ì²´ ì˜¤ë¥˜: {str(e)[:100]}...")
        st.caption("CloudWatch ë©”íŠ¸ë¦­ ì¡°íšŒ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´"):
            st.code(f"ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
            st.code(f"AWS ë¦¬ì „: us-east-1")
            
            # CloudWatch í´ë¼ì´ì–¸íŠ¸ê°€ ì •ì˜ëœ ê²½ìš°ì—ë§Œ í‘œì‹œ
            if 'cloudwatch_client' in locals() and cloudwatch_client is not None:
                st.code(f"CloudWatch í´ë¼ì´ì–¸íŠ¸: {type(cloudwatch_client)}")
                
                # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ í™•ì¸ ì‹œë„
                try:
                    metrics = cloudwatch_client.list_metrics(Namespace='AWS/Bedrock')
                    st.code(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ ìˆ˜: {len(metrics.get('Metrics', []))}")
                except Exception as list_error:
                    st.code(f"ë©”íŠ¸ë¦­ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(list_error)}")
            else:
                st.code("CloudWatch í´ë¼ì´ì–¸íŠ¸: ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                st.code(f"ë©”íŠ¸ë¦­ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(list_error)}")

    # ì‹œìŠ¤í…œ ìƒíƒœ
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # Knowledge Base ìƒíƒœ í™•ì¸
    try:
        bedrock_agent_client = aws_manager.get_client('bedrock-agent-runtime', region_name='us-east-1')
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ Knowledge Base ìƒíƒœ í™•ì¸
        test_response = bedrock_agent_client.retrieve(
            knowledgeBaseId='SJJP9YYPHX',
            retrievalQuery={'text': 'test'},
            retrievalConfiguration={'vectorSearchConfiguration': {'numberOfResults': 1}}
        )
        st.success("âœ… Knowledge Base ì—°ê²°ë¨")
        st.caption(f"Knowledge Base ID: SJJP9YYPHX")
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ í‘œì‹œ
        result_count = len(test_response.get('retrievalResults', []))
        if result_count > 0:
            st.info(f"ğŸ“š Knowledge Base ì‘ë‹µ ê°€ëŠ¥")
        else:
            st.warning("âš ï¸ Knowledge Baseì— ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
    except Exception as e:
        st.error("âŒ Knowledge Base ì—°ê²° ì‹¤íŒ¨")
        st.caption(f"ì˜¤ë¥˜: {str(e)[:100]}...")
    
    st.divider()
    st.subheader("ğŸ¤– AI ëª¨ë¸ ì •ë³´")
    st.info("**Nova Micro + Nova Pro + Translation**")
    st.caption("â€¢ âš¡ Nova Micro: ì¦‰ê°ì ì¸ ì´ˆê¸° ì‘ë‹µ")
    st.caption("â€¢ ğŸ§  Nova Pro: ìƒì„¸í•œ ìµœì¢… ë‹µë³€")
    st.caption("â€¢ ğŸŒ Nova Pro: ê³ í’ˆì§ˆ ê²Œì„ ìš©ì–´ ë²ˆì—­")
    st.caption("â€¢ ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì‘ë‹µ")
    st.caption("â€¢ ğŸ“¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°")
    st.caption("â€¢ ğŸ’° í”„ë¡¬í”„íŠ¸ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆì•½")
    
    st.divider()
    st.subheader("ğŸ’¡ ì‚¬ìš© íŒ")
    if language_code == "English":
        st.markdown("""
        - **Keyword Search**: "Amazon Survival", "CS Response" etc.
        - **Specific Questions**: "How to fix game execution error?"
        - **Complex Questions**: "Amazon Survival characters and worldview"
        - **Development Related**: "Local server setup", "Dev environment"
        - References previous conversations
        - **New Features**: Quick initial response + Detailed final answer
        - **Translation**: Real-time gaming terminology translation
        """)
    else:
        st.markdown("""
        - **í‚¤ì›Œë“œ ê²€ìƒ‰**: "ì•„ë§ˆì¡´ ìƒì¡´ê¸°", "CS ë‹µë³€" ë“±
        - **êµ¬ì²´ì  ì§ˆë¬¸**: "ê²Œì„ ì‹¤í–‰ ì˜¤ë¥˜ í•´ê²° ë°©ë²•ì€?"
        - **ë³µí•© ì§ˆë¬¸**: "ì•„ë§ˆì¡´ ìƒì¡´ê¸° ë“±ì¥ì¸ë¬¼ê³¼ ì„¸ê³„ê´€"
        - **ê°œë°œ ê´€ë ¨**: "ë¡œì»¬ì„œë²„ ì„¤ì •", "ê°œë°œ í™˜ê²½"
        - ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•©ë‹ˆë‹¤
        - **ìƒˆë¡œìš´ ê¸°ëŠ¥**: ë¹ ë¥¸ ì´ˆê¸° ì‘ë‹µ + ìƒì„¸í•œ ìµœì¢… ë‹µë³€
        - **ë²ˆì—­ ê¸°ëŠ¥**: ì‹¤ì‹œê°„ ê²Œì„ ìš©ì–´ ë²ˆì—­
        """)
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ / Clear Chat"):
        st.session_state.messages = []
        st.rerun()

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

if not st.session_state.messages:
    with st.chat_message("assistant"):
        if language_code == "English":
            st.markdown("""
            Hello! I'm the Global CS Chatbot. ğŸŒ
            
            **Upgraded with Nova Micro + Nova Pro + Translation** for faster and more accurate responses!
            
            âš¡ **Nova Micro**: Instant initial response within 1 second  
            ğŸ§  **Nova Pro**: Detailed final response generated in background  
            ğŸŒ **Translation**: Real-time gaming terminology translation  
            ğŸ”„ **Parallel Processing**: Both models work simultaneously to minimize latency
            
            I can answer questions based on **36 documents** and provide real-time translation for gaming terminology.
            Feel free to ask me anything!
            
            **Example Questions:**
            - "Tell me about Amazon Survival in detail"
            - "What are the CS response formats and guidelines?"
            - "How to solve game execution problems?"
            - "Please explain local server setup step by step"
            - "What are the characteristics of Amazon Survival characters?"
            """)
        else:
            st.markdown("""
            ì•ˆë…•í•˜ì„¸ìš”! ê¸€ë¡œë²Œ CS ì±—ë´‡ì…ë‹ˆë‹¤. ğŸŒ
            
            **Nova Micro + Nova Pro + Translation**ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œë˜ì–´ ë”ìš± ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤!
            
            âš¡ **Nova Micro**: 1ì´ˆ ì´ë‚´ ì¦‰ê°ì ì¸ ì´ˆê¸° ì‘ë‹µ  
            ğŸ§  **Nova Pro**: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìƒì„¸í•œ ìµœì¢… ë‹µë³€ ìƒì„±  
            ğŸŒ **ë²ˆì—­ ê¸°ëŠ¥**: ì‹¤ì‹œê°„ ê²Œì„ ìš©ì–´ ë²ˆì—­  
            ğŸ”„ **ë³‘ë ¬ ì²˜ë¦¬**: ë‘ ëª¨ë¸ì´ ë™ì‹œì— ì‘ì—…í•˜ì—¬ ì§€ì—° ì‹œê°„ ìµœì†Œí™”
            
            **36ê°œì˜ ë¬¸ì„œ**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , ê²Œì„ ìš©ì–´ ì‹¤ì‹œê°„ ë²ˆì—­ì„ ì œê³µí•©ë‹ˆë‹¤.
            ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!
            
            **ì˜ˆì‹œ ì§ˆë¬¸:**
            - "ì•„ë§ˆì¡´ ìƒì¡´ê¸°ì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”"
            - "CS ë‹µë³€ í˜•ì‹ê³¼ ê°€ì´ë“œë¼ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            - "ê²Œì„ ì‹¤í–‰ ê´€ë ¨ ë¬¸ì œ í•´ê²° ë°©ë²•ì€?"
            - "ë¡œì»¬ì„œë²„ ì„¤ì • ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”"
            - "ì•„ë§ˆì¡´ ìƒì¡´ê¸° ë“±ì¥ì¸ë¬¼ë“¤ì˜ íŠ¹ì§•ì€?"
            """)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and "references" in message:
            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ / Reference Documents"):
                for doc in message["references"]:
                    st.markdown(f"**{doc['title']}** (ì ìˆ˜: {doc.get('score', 0)})")
                    if 'matched_keywords' in doc and doc['matched_keywords']:
                        st.caption(f"ğŸ” ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {', '.join(doc['matched_keywords'])}")
                    st.markdown(doc['content'][:600] + ("..." if len(doc['content']) > 600 else ""))
                    if doc['url'] != '#':
                        st.markdown(f"[ì›ë³¸ ë³´ê¸°]({doc['url']})")
                    st.divider()

# ì±„íŒ… ì…ë ¥
if language_code == "English":
    prompt_placeholder = "Enter your question..."
else:
    prompt_placeholder = "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."

if prompt := st.chat_input(prompt_placeholder):
    # ë²ˆì—­ ê¸°ëŠ¥ ì¶”ê°€ - ì‚¬ìš©ì ì…ë ¥ì´ ë‹¤ë¥¸ ì–¸ì–´ì¸ ê²½ìš° ë²ˆì—­
    original_prompt = prompt
    detected_language = "Korean" if re.search(r'[ê°€-í£]', prompt) else "English"
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ì™€ ì…ë ¥ ì–¸ì–´ê°€ ë‹¤ë¥¸ ê²½ìš° ë²ˆì—­
    if (language_code == "Korean" and detected_language == "English") or \
       (language_code == "English" and detected_language == "Korean"):
        
        with st.spinner("Nova Proê°€ ì§ˆë¬¸ì„ ë²ˆì—­ ì¤‘... / Nova Pro is translating question..."):
            translation_result = translate_text_with_caching(prompt, language_code)
            translated_prompt = translation_result['translated_text']
            
            # ë²ˆì—­ëœ ì§ˆë¬¸ í‘œì‹œ
            st.info(f"ğŸ”„ ë²ˆì—­ëœ ì§ˆë¬¸ / Translated Question: {translated_prompt}")
            prompt = translated_prompt
    
    st.session_state.messages.append({"role": "user", "content": original_prompt})
    with st.chat_message("user"):
        st.markdown(original_prompt)

    with st.chat_message("assistant"):
        # Knowledge Baseì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
        context_docs = search_knowledge_base(prompt)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
        if context_docs:
            if language_code == "English":
                st.caption(f"ğŸ” Found {len(context_docs)} documents from Knowledge Base")
            else:
                st.caption(f"ğŸ” Knowledge Baseì—ì„œ {len(context_docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
        else:
            if language_code == "English":
                st.caption("ğŸ” No documents found in Knowledge Base")
            else:
                st.caption("ğŸ” Knowledge Baseì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ")
            
        # ë“€ì–¼ ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
        answer = generate_dual_answer(prompt, context_docs, st.session_state.messages, language_code)
        
        if context_docs:
            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ / Reference Documents"):
                for doc in context_docs:
                    st.markdown(f"**{doc['title']}** (ì ìˆ˜: {doc.get('score', 0):.3f})")
                    st.markdown(doc['content'][:600] + ("..." if len(doc['content']) > 600 else ""))
                    if doc['url'] != '#':
                        st.markdown(f"[ì›ë³¸ ë³´ê¸°]({doc['url']})")
                    st.divider()
            
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer,
                "references": context_docs
            })
        else:
            st.session_state.messages.append({"role": "assistant", "content": answer})

st.divider()
if language_code == "English":
    st.caption("ğŸ”„ Knowledge Base provides real-time intelligent search.")
    st.caption("âš¡ Provides fast and accurate responses with Nova Micro + Nova Pro dual model.")
    st.caption("ğŸŒ Real-time gaming terminology translation available.")
    st.caption("ğŸ“š Powered by Amazon Bedrock Knowledge Base.")
else:
    st.caption("ğŸ”„ Knowledge Baseê°€ ì‹¤ì‹œê°„ ì§€ëŠ¥í˜• ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.")
    st.caption("âš¡ Nova Micro + Nova Pro ë“€ì–¼ ëª¨ë¸ë¡œ ë¹ ë¥´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")
    st.caption("ğŸŒ ì‹¤ì‹œê°„ ê²Œì„ ìš©ì–´ ë²ˆì—­ì„ ì§€ì›í•©ë‹ˆë‹¤.")
    st.caption("ğŸ“š Amazon Bedrock Knowledge Baseë¡œ êµ¬ë™ë©ë‹ˆë‹¤.")
